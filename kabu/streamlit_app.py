import streamlit as st
import pandas as pd
import yfinance as yf
from curl_cffi import requests as curl_requests
from curl_cffi.requests.exceptions import ImpersonateError, HTTPError
from bs4 import BeautifulSoup
import logging
import time
import re
from datetime import datetime, date
from collections import OrderedDict
import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib
import unicodedata
import random
import json
import os
import google.generativeai as genai

# ==============================================================================
# 1. ãƒ­ã‚°è¨­å®š
# ==============================================================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ==============================================================================
# 1.1. Google Gemini APIã®è¨­å®š
# ==============================================================================
# APIã‚­ãƒ¼ã‚’ç›´æ¥ã‚³ãƒ¼ãƒ‰ã«è¨­å®šã—ã¾ã™
try:
    api_key = "AIzaSyCfRAXzND5SX5gECeq8HGX0_5mSIcFgJMY"
    genai.configure(api_key=api_key)
    logger.info("Gemini APIã‚­ãƒ¼ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã§è¨­å®šã—ã¾ã—ãŸã€‚")
except Exception as e:
    st.error(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚­ãƒ¼ãŒæœ‰åŠ¹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()


def generate_prompt(ticker_code, candidate_list_str=None):
    """AIé¡ä¼¼éŠ˜æŸ„æ¤œç´¢ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ï¼ˆæ”¹å–„ç‰ˆï¼‰"""

    task_instruction = ""
    if candidate_list_str:
        task_instruction = f"""
# æœ€é‡è¦ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®ã€å€™è£œä¼æ¥­ãƒªã‚¹ãƒˆã€‘ã®ä¸­ã‹ã‚‰ã€å‰ææ¡ä»¶ã§æŒ‡å®šã•ã‚ŒãŸä¼æ¥­ã«æœ€ã‚‚äº‹æ¥­å†…å®¹ãŒé¡ä¼¼ã™ã‚‹ä¼æ¥­ã‚’æœ€å¤§5ç¤¾é¸å®šã—ã¦ãã ã•ã„ã€‚ãƒªã‚¹ãƒˆã«ãªã„ä¼æ¥­ã¯çµ¶å¯¾ã«å‡ºåŠ›ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚

ã€å€™è£œä¼æ¥­ãƒªã‚¹ãƒˆã€‘
{candidate_list_str}
"""
    else:
        task_instruction = """
# ã‚¿ã‚¹ã‚¯
å‰ææ¡ä»¶ã§æŒ‡å®šã•ã‚ŒãŸä¼æ¥­ã«å¯¾ã—ã€æ—¥æœ¬å¸‚å ´å…¨ä½“ã‹ã‚‰æœ€ã‚‚äº‹æ¥­å†…å®¹ãŒé¡ä¼¼ã™ã‚‹ä¼æ¥­ã‚’æœ€å¤§5ç¤¾é¸å®šã—ã¦ãã ã•ã„ã€‚
"""

    return f"""
ã‚ãªãŸã¯ã€è±Šå¯ŒãªçµŒé¨“ã‚’æŒã¤ãƒ—ãƒ­ã®æ ªå¼ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è¦ä»¶ã«å¾“ã„ã€æŒ‡å®šã•ã‚ŒãŸä¼æ¥­ã«æœ€ã‚‚é©ã—ãŸãƒ”ã‚¢ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆç«¶åˆä¼æ¥­ç¾¤ï¼‰ã‚’é¸å®šã—ã¦ãã ã•ã„ã€‚

# ç›®çš„
æŒ‡å®šã•ã‚ŒãŸä¼æ¥­ã«ã¤ã„ã¦ã€æŠ•è³‡ä¾¡å€¤è©•ä¾¡ï¼ˆãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚„æˆ¦ç•¥çš„ãªç›¸å¯¾æ¯”è¼ƒåˆ†æã‚’è¡Œã†ä¸Šã§ã€æœ€ã‚‚æ¯”è¼ƒå¯èƒ½æ€§ã®é«˜ã„ãƒ”ã‚¢ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å®¢è¦³çš„ã‹ã¤è«–ç†çš„ãªæ ¹æ‹ ã«åŸºã¥ã„ã¦ç‰¹å®šã™ã‚‹ã€‚

# å‡ºåŠ›å½¢å¼
éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§5ã¤ã¾ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
ä¾‹: 9984,4755,9432,9433,6758

# ç¦æ­¢äº‹é …
- å˜ã«ã€Œå¤§æ‰‹æ—¥æœ¬ä¼æ¥­ã€ã€Œæœ‰åãƒ–ãƒ©ãƒ³ãƒ‰ã€ã€Œå¤šå›½ç±ä¼æ¥­ã€ã¨ã„ã£ãŸæ›–æ˜§ã§é«˜ãƒ¬ãƒ™ãƒ«ãªå…±é€šç‚¹ã ã‘ã§é¡ä¼¼ä¼æ¥­ã‚’é¸å®šã—ãªã„ã§ãã ã•ã„ã€‚
- å¿…ãšã€ä¼æ¥­ã®ä¸»åŠ›äº‹æ¥­ï¼ˆæœ€ã‚‚åç›Šã‚’ä¸Šã’ã¦ã„ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼‰ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‚’æœ€å„ªå…ˆã®åˆ¤æ–­åŸºæº–ã¨ã—ã¦ãã ã•ã„ã€‚

# è‰¯ã„ä¾‹ã¨æ‚ªã„ä¾‹
- è‰¯ã„ä¾‹ï¼šãƒ¤ã‚¯ãƒ«ãƒˆï¼ˆ2267ï¼‰ã‚’åˆ†æã™ã‚‹å ´åˆã€åŒã˜é£²æ–™ãƒ»é£Ÿå“ãƒ¡ãƒ¼ã‚«ãƒ¼ã§ã‚ã‚‹æ£®æ°¸ä¹³æ¥­ï¼ˆ2264ï¼‰ã‚„ã‚­ãƒªãƒ³HDï¼ˆ2503ï¼‰ã¯é©åˆ‡ãªé¡ä¼¼ä¼æ¥­ã§ã™ã€‚
- æ‚ªã„ä¾‹ï¼šãƒ¤ã‚¯ãƒ«ãƒˆï¼ˆ2267ï¼‰ã«å¯¾ã—ã¦ã€äº‹æ¥­å†…å®¹ãŒå…¨ãç•°ãªã‚‹ã‚½ãƒ‹ãƒ¼ï¼ˆ6758ï¼‰ã‚„ä»»å¤©å ‚ï¼ˆ7974ï¼‰ã¯ä¸é©åˆ‡ãªé¡ä¼¼ä¼æ¥­ã§ã™ã€‚

# å‰ææ¡ä»¶
åˆ†æå¯¾è±¡ä¼æ¥­: è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ {ticker_code}

{task_instruction}
"""

# ==============================================================================
# 1.5. ã‚¢ã‚¯ã‚»ã‚¹ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
# ==============================================================================
@st.cache_data
def get_supported_browsers():
    """
    å®Ÿè¡Œç’°å¢ƒã§åˆ©ç”¨å¯èƒ½ãªãƒ–ãƒ©ã‚¦ã‚¶å½è£…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‹•çš„ã«ãƒ†ã‚¹ãƒˆã—ã€
    ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    potential_browsers = [
        "chrome124", "chrome123", "chrome120", "chrome119", "chrome117", "chrome116",
        "chrome120_android", "safari17_0"
    ]
    supported = []
    logger.info("åˆ©ç”¨å¯èƒ½ãªãƒ–ãƒ©ã‚¦ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã‚’é–‹å§‹ã—ã¾ã™...")
    for browser in potential_browsers:
        try:
            s = curl_requests.Session()
            s.impersonate = browser
            s.get("https://www.google.com", timeout=10)
            supported.append(browser)
            logger.info(f"  âœ… ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« '{browser}' ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚")
        except ImpersonateError:
            logger.warning(f"  âŒ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« '{browser}' ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        except Exception as e:
            logger.warning(f"  âš ï¸ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« '{browser}' ã®ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    if not supported:
        logger.error("é‡å¤§: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.error("åˆ©ç”¨å¯èƒ½ãªãƒ–ãƒ©ã‚¦ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚")
    return supported

class BrowserRotator:
    def __init__(self):
        supported_list = get_supported_browsers()
        if not supported_list:
            raise RuntimeError("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ãŒãªã„ãŸã‚ã€å‡¦ç†ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚")
        chrome_weights = {
            "chrome116": 5, "chrome117": 8, "chrome119": 20,
            "chrome120": 25, "chrome123": 15, "chrome124": 12
        }
        self.chrome_versions = []
        self.mobile_versions = []
        self.safari_versions = []
        for browser in supported_list:
            if "android" in browser:
                self.mobile_versions.append(browser)
            elif browser.startswith("safari"):
                self.safari_versions.append(browser)
            elif browser.startswith("chrome"):
                weight = chrome_weights.get(browser, 1)
                self.chrome_versions.append((browser, weight))
        logger.info(f"åˆæœŸåŒ–å®Œäº†ã€‚Chrome: {[v[0] for v in self.chrome_versions]}, Mobile: {self.mobile_versions}, Safari: {self.safari_versions}")

    def get_random_browser(self):
        browser_types = []
        if self.chrome_versions: browser_types.append(("chrome", 65))
        if self.mobile_versions: browser_types.append(("mobile", 25))
        if self.safari_versions: browser_types.append(("safari", 10))
        if not browser_types:
            if self.chrome_versions:
                versions, weights = zip(*self.chrome_versions)
                return random.choices(versions, weights=weights, k=1)[0]
            raise RuntimeError("å›è»¢ã«ä½¿ç”¨ã§ãã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        population, weights = zip(*browser_types)
        chosen_type = random.choices(population, weights=weights, k=1)[0]
        if chosen_type == "chrome":
            versions, weights = zip(*self.chrome_versions)
            return random.choices(versions, weights=weights, k=1)[0]
        elif chosen_type == "mobile":
            return random.choice(self.mobile_versions)
        else:
            return random.choice(self.safari_versions)

# ==============================================================================
# 2. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==============================================================================
def create_copy_button(text_to_copy: str, button_text: str, key: str):
    js_escaped_text = json.dumps(text_to_copy)
    button_id = f"copy-btn-{key}"
    html_code = f"""
    <style>
        #{button_id} {{
            display: inline-flex; align-items: center; justify-content: center;
            font-weight: 400; padding: 0.25rem 0.75rem; border-radius: 0.5rem;
            min-height: 38.4px; margin: 0px; line-height: 1.6; color: #31333F;
            background-color: #FFFFFF; border: 1px solid rgba(49, 51, 63, 0.2);
            cursor: pointer; transition: all .2s ease-in-out;
        }}
        #{button_id}:hover {{ border-color: #FF4B4B; color: #FF4B4B; }}
        #{button_id}.copied {{ border-color: #008000; color: #008000; }}
    </style>
    <button id="{button_id}">{button_text}</button>
    <script>
        document.getElementById('{button_id}').addEventListener('click', function() {{
            navigator.clipboard.writeText({js_escaped_text}).then(() => {{
                let btn = document.getElementById('{button_id}');
                const originalText = btn.innerHTML;
                btn.innerHTML = 'âœ… Copied!';
                btn.classList.add('copied');
                setTimeout(() => {{
                    btn.innerHTML = originalText;
                    btn.classList.remove('copied');
                }}, 2000);
            }}).catch(err => {{ console.error('Failed to copy: ', err); }});
        }});
    </script>
    """
    st.components.v1.html(html_code, height=50)

# ==============================================================================
# 3. éŠ˜æŸ„æ¤œç´¢ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
# ==============================================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
JPX_STOCK_LIST_PATH = os.path.join(BASE_DIR, "jpx_list.xls")

@st.cache_data
def load_jpx_stock_list():
    try:
        df = pd.read_excel(JPX_STOCK_LIST_PATH, header=None, engine='xlrd')
        # â˜…ä¿®æ­£: æ¥­ç¨®ã‚³ãƒ¼ãƒ‰ã®ã‚«ãƒ©ãƒ (4)ã‚‚èª­ã¿è¾¼ã‚€
        if df.shape[1] < 6:
            st.error(f"éŠ˜æŸ„ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«({JPX_STOCK_LIST_PATH})ã®å½¢å¼ãŒæƒ³å®šã¨ç•°ãªã‚Šã¾ã™ã€‚")
            return pd.DataFrame(columns=['code', 'name', 'market', 'sector_code', 'sector', 'normalized_name'])
        df = df.iloc[:, [1, 2, 3, 4, 5]]
        df.columns = ['code', 'name', 'market', 'sector_code', 'sector']
        df.dropna(subset=['code', 'name', 'sector_code'], inplace=True)

        # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—ã¨ã—ã¦ç¢ºå®Ÿã«å‡¦ç†ã™ã‚‹
        def clean_code(x):
            if pd.isna(x):
                return ""
            if isinstance(x, float):
                return str(int(x))
            return str(x).strip().upper()

        df['code'] = df['code'].apply(clean_code)
        # æ¥­ç¨®ã‚³ãƒ¼ãƒ‰ã‚’æ•°å€¤å‹ã«å¤‰æ›
        df['sector_code'] = pd.to_numeric(df['sector_code'], errors='coerce').astype('Int64')
        df = df[df['code'].str.fullmatch(r'(\d{4}|\d{3}[A-Z])', na=False)]
        df['normalized_name'] = df['name'].apply(normalize_text)
        logger.info(f"éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {len(df)}ä»¶")
        return df
    except FileNotFoundError:
        st.error(f"éŠ˜æŸ„ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« ({JPX_STOCK_LIST_PATH}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame(columns=['code', 'name', 'market', 'sector_code', 'sector', 'normalized_name'])
    except Exception as e:
        if "xlrd" in str(e).lower():
            st.error("Excelãƒ•ã‚¡ã‚¤ãƒ«(.xls)ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª 'xlrd' ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            st.error(f"éŠ˜æŸ„ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame(columns=['code', 'name', 'market', 'sector_code', 'sector', 'normalized_name'])

def normalize_text(text: str) -> str:
    if not isinstance(text, str): return ""
    text = unicodedata.normalize('NFKC', text)
    text = "".join([chr(ord(c) + 96) if "ã" <= c <= "ã‚“" else c for c in text])
    text = text.upper()
    remove_words = ['ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹', 'ã‚°ãƒ«ãƒ¼ãƒ—', 'æ ªå¼ä¼šç¤¾', 'åˆåŒä¼šç¤¾', 'æœ‰é™ä¼šç¤¾', '(æ ª)', '(åŒ)', '(æœ‰)', ' ', 'ã€€', 'ãƒ»', '-']
    for word in remove_words:
        text = text.replace(word, '')
    return text.strip()

# ==============================================================================
# æˆ¦ç•¥ã¨æ¥­ç¨®ã®å®šç¾©
# ==============================================================================
STRATEGY_WEIGHTS = {
    "âš–ï¸ ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆãƒãƒ©ãƒ³ã‚¹ï¼‰": {"safety": 0.25, "value": 0.25, "quality": 0.25, "growth": 0.25},
    "ğŸ’ ãƒãƒªãƒ¥ãƒ¼é‡è¦–ï¼ˆä¾¡å€¤é‡è¦–ï¼‰": {"safety": 0.35, "value": 0.40, "quality": 0.20, "growth": 0.05},
    "ğŸš€ ã‚°ãƒ­ãƒ¼ã‚¹é‡è¦–ï¼ˆæˆé•·é‡è¦–ï¼‰": {"safety": 0.10, "value": 0.20, "quality": 0.35, "growth": 0.35},
    "ğŸ›¡ï¸ å¥å…¨æ€§é‡è¦–ï¼ˆå®‰å…¨ç¬¬ä¸€ï¼‰": {"safety": 0.50, "value": 0.25, "quality": 0.15, "growth": 0.10}
}
# â˜…è¿½åŠ : ã‚·ã‚¯ãƒªã‚«ãƒ«éŠ˜æŸ„ã®æ¥­ç¨®ã‚³ãƒ¼ãƒ‰ã‚’å®šç¾©
CYCLICAL_SECTOR_CODES = {
    1050, 3100, 3150, 3200, 3300, 3350, 3400, 3450, 3500, 3550, 3600, 3650, 3700, 3750, 5050, 5100, 5150, 5200, 6050
}

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¯ãƒ©ã‚¹
# ==============================================================================
class IntegratedDataHandler:
    def __init__(self):
        self.stock_list_df = load_jpx_stock_list()
        self.browser_rotator = BrowserRotator()
        self.session = None

    def _reset_session(self):
        logger.info("æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã™...")
        self.session = curl_requests.Session()
        try:
            selected_version = self.browser_rotator.get_random_browser()
            self.session.impersonate = selected_version
            logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å½è£…ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã—ã¦ '{selected_version}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            self.session.get("https://www.buffett-code.com/", timeout=20)
            logger.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", exc_info=True)
            st.error(f"ãƒãƒ•ã‚§ãƒƒãƒˆã‚³ãƒ¼ãƒ‰ã¸ã®åˆæœŸã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
            self.session = None

    def get_ticker_info_from_query(self, query: str) -> dict | None:
        query_original = query.strip()
        query_upper = query_original.upper()
        if re.fullmatch(r'(\d{4}|\d{3}[A-Z])', query_upper):
            code_to_search = query_upper
            if not self.stock_list_df.empty:
                stock_data = self.stock_list_df[self.stock_list_df['code'] == code_to_search]
                if not stock_data.empty:
                    return stock_data.iloc[0].to_dict()
                else:
                    logger.warning(f"éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ '{code_to_search}' ã¯ãƒªã‚¹ãƒˆã«å­˜åœ¨ã—ã¾ã›ã‚“ãŒã€åˆ†æã‚’è©¦ã¿ã¾ã™ã€‚")
                    return {'code': code_to_search, 'name': f'éŠ˜æŸ„ {code_to_search}', 'sector': 'æ¥­ç¨®ä¸æ˜', 'sector_code': None}
            return {'code': code_to_search, 'name': f'éŠ˜æŸ„ {code_to_search}', 'sector': 'æ¥­ç¨®ä¸æ˜', 'sector_code': None}
        if self.stock_list_df.empty: return None
        normalized_query = normalize_text(query_original)
        if not normalized_query: return None
        matches = self.stock_list_df[self.stock_list_df['normalized_name'].str.contains(normalized_query, na=False)].copy()
        if not matches.empty:
            prime_matches = matches[matches['market'].str.contains('ãƒ—ãƒ©ã‚¤ãƒ ', na=False)]
            target_df = prime_matches if not prime_matches.empty else matches
            target_df.loc[:, 'diff'] = target_df['normalized_name'].apply(lambda x: abs(len(x) - len(normalized_query)))
            stock_data = target_df.sort_values(by='diff').iloc[0]
            logger.info(f"æ¤œç´¢ã‚¯ã‚¨ãƒª '{query_original}' ã‹ã‚‰éŠ˜æŸ„ '{stock_data['name']} ({stock_data['code']})' ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚")
            return stock_data.to_dict()
        logger.warning(f"æ¤œç´¢ã‚¯ã‚¨ãƒª '{query_original}' ã«ä¸€è‡´ã™ã‚‹éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    YFINANCE_TRANSLATION_MAP = {
        'Total Revenue': 'å£²ä¸Šé«˜', 'Revenue': 'å£²ä¸Šé«˜', 'Operating Income': 'å–¶æ¥­åˆ©ç›Š', 'Operating Expense': 'å–¶æ¥­è²»ç”¨',
        'Cost Of Revenue': 'å£²ä¸ŠåŸä¾¡', 'Gross Profit': 'å£²ä¸Šç·åˆ©ç›Š', 'Selling General And Administration': 'è²©å£²è²»åŠã³ä¸€èˆ¬ç®¡ç†è²»',
        'Research And Development': 'ç ”ç©¶é–‹ç™ºè²»', 'Pretax Income': 'ç¨å¼•å‰åˆ©ç›Š', 'Tax Provision': 'æ³•äººç¨',
        'Net Income': 'å½“æœŸç´”åˆ©ç›Š', 'Net Income Common Stockholders': 'è¦ªä¼šç¤¾æ ªä¸»ã«å¸°å±ã™ã‚‹å½“æœŸç´”åˆ©ç›Š', 'Basic EPS': '1æ ªå½“ãŸã‚Šåˆ©ç›Š (EPS)',
        'Diluted EPS': 'å¸Œè–„åŒ–å¾ŒEPS', 'Total Assets': 'ç·è³‡ç”£', 'Current Assets': 'æµå‹•è³‡ç”£',
        'Cash And Cash Equivalents': 'ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©', 'Cash': 'ç¾é‡‘', 'Receivables': 'å£²ä¸Šå‚µæ¨©', 'Inventory': 'æ£šå¸è³‡ç”£',
        'Total Non Current Assets': 'å›ºå®šè³‡ç”£', 'Net PPE': 'æœ‰å½¢å›ºå®šè³‡ç”£', 'Goodwill And Other Intangible Assets': 'ã®ã‚Œã‚“åŠã³ãã®ä»–ç„¡å½¢å›ºå®šè³‡ç”£',
        'Total Liabilities Net Minority Interest': 'è² å‚µåˆè¨ˆ', 'Current Liabilities': 'æµå‹•è² å‚µ', 'Payables And Accrued Expenses': 'æ”¯æ‰•æ‰‹å½¢åŠã³è²·æ›é‡‘',
        'Current Debt': 'çŸ­æœŸæœ‰åˆ©å­è² å‚µ', 'Total Non Current Liabilities Net Minority Interest': 'å›ºå®šè² å‚µ', 'Long Term Debt': 'é•·æœŸæœ‰åˆ©å­è² å‚µ',
        'Total Equity Gross Minority Interest': 'ç´”è³‡ç”£åˆè¨ˆ', 'Stockholders Equity': 'æ ªä¸»è³‡æœ¬', 'Retained Earnings': 'åˆ©ç›Šå‰°ä½™é‡‘',
        'Cash Flow From Continuing Operating Activities': 'å–¶æ¥­ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼', 'Cash Flow From Continuing Investing Activities': 'æŠ•è³‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼',
        'Cash Flow From Continuing Financing Activities': 'è²¡å‹™ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼', 'Net Change In Cash': 'ç¾é‡‘ã®å¢—æ¸›é¡', 'Free Cash Flow': 'ãƒ•ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼',
    }

    def get_html_soup(self, url: str, retries: int = 3) -> BeautifulSoup | None:
        for attempt in range(retries):
            if self.session is None:
                logger.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç„¡åŠ¹ã§ã™ã€‚æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚")
                self._reset_session()
                if self.session is None:
                    st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å†åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                    return None
            logger.info(f"URLã«ã‚¢ã‚¯ã‚»ã‚¹è©¦è¡Œ ({attempt + 1}/{retries}): {url}")
            try:
                headers = {
                    'Referer': 'https://www.buffett-code.com/',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                    'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Sec-Ch-Ua': f'"Chromium";v="{self.session.impersonate.split("chrome")[1]}", "Not/A)Brand";v="99"',
                    'Sec-Ch-Ua-Mobile': '?0',
                    'Sec-Ch-Ua-Platform': '"Windows"',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'same-origin',
                    'Sec-Fetch-User': '?1',
                    'Upgrade-Insecure-Requests': '1',
                }
                wait_time = random.uniform(4.0, 7.0) * (attempt + 1)
                logger.info(f"{wait_time:.2f}ç§’å¾…æ©Ÿã—ã¾ã™...")
                time.sleep(wait_time)
                response = self.session.get(url, timeout=30, headers=headers)
                response.raise_for_status()
                logger.info(f"URLã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}): {url}")
                return BeautifulSoup(response.content, 'html.parser')
            except HTTPError as e:
                logger.error(f"HTTPã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ (è©¦è¡Œ {attempt + 1}/{retries}): {url}, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {e.response.status_code}, ã‚¨ãƒ©ãƒ¼: {e}", exc_info=False)
                if e.response.status_code in [403, 405, 429]:
                    logger.warning("ã‚¢ã‚¯ã‚»ã‚¹ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦å†è©¦è¡Œã—ã¾ã™ã€‚")
                    self._reset_session()
                elif e.response.status_code >= 500:
                    time.sleep(10)
            except Exception as e:
                logger.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ (è©¦è¡Œ {attempt + 1}/{retries}): {url}, ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                self._reset_session()
        st.error(f"ãƒãƒ•ã‚§ãƒƒãƒˆã‚³ãƒ¼ãƒ‰ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ ({retries}å›è©¦è¡Œå¾Œ)ã€‚ã‚µã‚¤ãƒˆãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã‹ã€IPãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        return None

    def get_risk_free_rate(self) -> float | None:
        url = "https://jp.investing.com/rates-bonds/japan-10-year-bond-yield"
        logger.info(f"ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆå–å¾—è©¦è¡Œ (æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½¿ç”¨): {url}")
        try:
            with curl_requests.Session() as temp_session:
                impersonate_version = self.browser_rotator.get_random_browser()
                temp_session.impersonate = impersonate_version
                logger.info(f"Investing.comã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã« '{impersonate_version}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                time.sleep(random.uniform(1.0, 2.0))
                response = temp_session.get(url, timeout=25)
                response.raise_for_status()
                soup = BeautifulSoup(response.content, 'html.parser')
                yield_element = soup.find('div', attrs={'data-test': 'instrument-price-last'})
                if not yield_element: yield_element = soup.find('div', class_=re.compile(r'instrument-price_last__'))
                if not yield_element: yield_element = soup.select_one('[data-test="instrument-price-last"], .instrument-price_last__2wE7v')
                if yield_element:
                    rate = float(yield_element.text.strip()) / 100
                    logger.info(f"ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆã®å–å¾—ã«æˆåŠŸã—ã¾ã—ãŸ: {rate:.4f}")
                    return rate
                else:
                    logger.error("é‡‘åˆ©ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.toast("âš ï¸ é‡‘åˆ©ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", icon="âš ï¸")
                    return None
        except Exception as e:
            logger.error(f"ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", exc_info=True)
            st.toast("âš ï¸ ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", icon="âš ï¸")
            return None

    def get_listing_date(self, ticker_code: str) -> str | None:
        url = f"https://finance.yahoo.co.jp/quote/{ticker_code}.T/profile"
        logger.info(f"ä¸Šå ´å¹´æœˆæ—¥å–å¾—è©¦è¡Œ (æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½¿ç”¨): {url}")
        try:
            with curl_requests.Session() as temp_session:
                impersonate_version = self.browser_rotator.get_random_browser()
                temp_session.impersonate = impersonate_version
                logger.info(f"Yahoo Financeã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã« '{impersonate_version}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                time.sleep(random.uniform(1.0, 2.0))
                response = temp_session.get(url, timeout=25)
                response.raise_for_status()
                soup = BeautifulSoup(response.content, 'html.parser')
                th_tag = soup.find('th', string='ä¸Šå ´å¹´æœˆæ—¥')
                if th_tag:
                    td_tag = th_tag.find_next_sibling('td')
                    if td_tag:
                        listing_date_str = td_tag.get_text(strip=True)
                        logger.info(f"éŠ˜æŸ„ {ticker_code} ã®ä¸Šå ´å¹´æœˆæ—¥ '{listing_date_str}' ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
                        return listing_date_str
                logger.warning(f"éŠ˜æŸ„ {ticker_code} ã®ä¸Šå ´å¹´æœˆæ—¥ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return None
        except Exception as e:
            logger.error(f"ä¸Šå ´å¹´æœˆæ—¥ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ({ticker_code}): {e}", exc_info=True)
            st.toast(f"âš ï¸ {ticker_code}ã®ä¸Šå ´æ—¥å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", icon="âš ï¸")
            return None

    def parse_financial_value(self, s: str) -> int | float | None:
        s = str(s).replace(',', '').strip()
        if s in ['-', '---', '']: return None
        is_negative = s.startswith(('â–³', '-'))
        s = s.lstrip('â–³-')
        try:
            total = 0
            if 'å…†' in s: total += float(re.findall(r'(\d+\.?\d*)', s)[0]) * 1000000
            elif 'å„„' in s: total += float(re.findall(r'(\d+\.?\d*)', s)[0]) * 100
            elif 'ç™¾ä¸‡å††' in s: total += float(re.findall(r'(\d+\.?\d*)', s)[0])
            elif 'ä¸‡å††' in s: total += float(re.findall(r'(\d+\.?\d*)', s)[0]) * 0.01
            elif re.match(r'^\d+\.?\d*$', s): total = float(s)
            else: return s
            return -int(total) if is_negative else int(total)
        except (ValueError, TypeError, IndexError): return s

    def extract_all_financial_data(self, soup: BeautifulSoup) -> dict | None:
        financial_table = soup.find('table', class_='financial-table')
        if not financial_table: return None
        thead, tbody = financial_table.find('thead'), financial_table.find('tbody')
        if not thead or not tbody: return None
        period_headers = thead.find('tr').find_all('th')
        if len(period_headers) <= 1: return None
        valid_periods = []
        for i, th in enumerate(period_headers[1:]):
            header_text = th.text.strip()
            if header_text and "E" not in header_text.upper() and "C" not in header_text.upper():
                valid_periods.append({'name': header_text, 'index': i + 1})
        if not valid_periods: return None
        all_periods_data = OrderedDict()
        for row in tbody.find_all('tr'):
            cells = row.find_all(['th', 'td'])
            item_name = cells[0].text.strip()
            if not item_name or not re.search(r'[a-zA-Z\u3040-\u30FF\u4E00-\u9FFF]', item_name): continue
            for period in valid_periods:
                period_name = period['name']
                if period_name not in all_periods_data: all_periods_data[period_name] = {}
                if len(cells) > period['index']:
                    display_value = cells[period['index']].get_text(strip=True)
                    if display_value not in ['-', '---', '']:
                        all_periods_data[period_name][item_name] = {'display': display_value, 'raw': self.parse_financial_value(display_value)}
        return all_periods_data

    def get_latest_financial_data(self, financial_data_dict: dict) -> dict:
        latest_year, latest_month, latest_data = -1, -1, {}
        if not financial_data_dict: return {}
        for period_name, data in financial_data_dict.items():
            match = re.search(r'(\d{2,4})[./](\d{1,2})', period_name)
            if match:
                year_str, month_str = match.groups()
                year = int(year_str)
                month = int(month_str)
                year_full = 2000 + year if year < 50 else 1900 + year if year < 100 else year
                if year_full > latest_year or (year_full == latest_year and month > latest_month):
                    latest_year, latest_month, latest_data = year_full, month, data
        return latest_data

    def get_value(self, data_dict: dict, keys: list[str], log_name: str) -> any:
        for key in keys:
            if key in data_dict and data_dict[key].get('raw') is not None:
                value = data_dict[key]['raw']
                logger.info(f"âœ… {log_name}: é …ç›® '{key}' ã‹ã‚‰å€¤ ({value}) ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
                return value
        logger.warning(f"âš ï¸ {log_name}: é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (è©¦è¡Œã‚­ãƒ¼: {keys})")
        return None

    def format_yfinance_df(self, df: pd.DataFrame) -> pd.DataFrame:
        if df.empty: return df
        df_copy = df.copy()
        df_copy = df_copy.rename(index=self.YFINANCE_TRANSLATION_MAP)
        df_copy = df_copy.loc[df_copy.index.isin(self.YFINANCE_TRANSLATION_MAP.values())]
        df_copy.columns = [f"{col.year}.{col.month}" for col in df_copy.columns]
        exclude_rows = [name for name in df_copy.index if 'EPS' in name or 'æ¯”ç‡' in name or 'Rate' in name]
        for idx in df_copy.index:
            if idx not in exclude_rows:
                df_copy.loc[idx] = df_copy.loc[idx].apply(lambda x: x / 1e6 if pd.notna(x) else np.nan)
        return df_copy

    def _linear_interpolate(self, value, x1, y1, x2, y2):
        if value <= x1: return y1
        if value >= x2: return y2
        return y1 + (y2 - y1) * (value - x1) / (x2 - x1)

    def _score_net_cash_ratio(self, ratio):
        if ratio is None: return {'score': 0, 'evaluation': '---'}
        if ratio >= 1.0: return {'score': 100, 'evaluation': 'ã€è¶…å®‰å…¨åœãƒ»é‰„å£ã€‘'}
        if ratio >= 0.8: return {'score': self._linear_interpolate(ratio, 0.8, 90, 1.0, 100), 'evaluation': 'ã€æ¥µã‚ã¦å®‰å…¨ã€‘'}
        if ratio >= 0.5: return {'score': self._linear_interpolate(ratio, 0.5, 80, 0.8, 90), 'evaluation': 'ã€éå¸¸ã«å®‰å…¨ãƒ»å‰²å®‰ã€‘'}
        if ratio >= 0.2: return {'score': self._linear_interpolate(ratio, 0.2, 60, 0.5, 80), 'evaluation': 'ã€å®‰å…¨åœã€‘'}
        if ratio >= 0.1: return {'score': self._linear_interpolate(ratio, 0.1, 40, 0.2, 60), 'evaluation': 'ã€ã‚„ã‚„æ³¨æ„ã€‘'}
        if ratio > 0.01: return {'score': self._linear_interpolate(ratio, 0.01, 20, 0.1, 40), 'evaluation': 'ã€è¦æ³¨æ„ã€‘'}
        if ratio > 0: return {'score': self._linear_interpolate(ratio, 0, 0, 0.01, 20), 'evaluation': 'ã€è¦æ³¨æ„ã€‘'}
        return {'score': 0, 'evaluation': 'ã€è¦è­¦æˆ’ã€‘'}

    def _score_cn_per(self, cn_per, keijo_rieki, pe, trailing_eps):
        if pe is None and trailing_eps is not None and trailing_eps < 0: return {'score': 10, 'evaluation': 'ã€èµ¤å­—ä¼æ¥­ (EPSåŸºæº–)ã€‘'}
        if not (keijo_rieki is not None and keijo_rieki > 0): return {'score': 10, 'evaluation': 'ã€èµ¤å­—ãƒ»è¦æ³¨æ„ã€‘'}
        if cn_per is None: return {'score': 0, 'evaluation': '---'}
        if cn_per < 0: return {'score': 100, 'evaluation': 'ã€ç©¶æ¥µã®å‰²å®‰æ ªã€‘'}
        if cn_per < 2: return {'score': self._linear_interpolate(cn_per, 0, 100, 2, 95), 'evaluation': 'ã€ç¾é‡‘ã‚ˆã‚Šå®‰ã„ä¼šç¤¾ã€‘'}
        if cn_per < 4: return {'score': self._linear_interpolate(cn_per, 2, 95, 4, 90), 'evaluation': 'ã€æŠ•è³‡ã®ã©çœŸã‚“ä¸­ã€‘'}
        if cn_per < 7: return {'score': self._linear_interpolate(cn_per, 4, 90, 7, 80), 'evaluation': 'ã€ã¾ã‚ã€æ‚ªããªã„ã€‘'}
        if cn_per < 10: return {'score': self._linear_interpolate(cn_per, 7, 80, 10, 70), 'evaluation': 'ã€æ™®é€šã®ä¼šç¤¾ã€‘'}
        if cn_per < 15: return {'score': self._linear_interpolate(cn_per, 10, 70, 15, 50), 'evaluation': 'ã€å‰²é«˜ã«æ€ãˆã‚‹ã€‘'}
        return {'score': 20, 'evaluation': 'ã€è«–å¤–ãƒ»ãƒãƒ–ãƒ«ã€‘'}

    def _score_roic(self, roic, wacc):
        if roic is None: return {'score': 0, 'evaluation': '---'}
        roic_percent = roic * 100
        if roic_percent >= 20: return {'score': 100, 'evaluation': 'ã€ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ©ã‚¹ã€‘'}
        if roic_percent >= 15: return {'score': self._linear_interpolate(roic_percent, 15, 90, 20, 100), 'evaluation': 'ã€æ¥­ç•Œã®æ”¯é…è€…ã€‘'}
        if roic_percent >= 10: return {'score': self._linear_interpolate(roic_percent, 10, 80, 15, 90), 'evaluation': 'ã€å„ªã‚ŒãŸè³‡æœ¬åŠ¹ç‡ã€‘'}
        if roic_percent >= 7: return {'score': self._linear_interpolate(roic_percent, 7, 70, 10, 80), 'evaluation': 'ã€å„ªè‰¯ã®å…¥ã‚Šå£ã€‘'}
        if wacc is not None:
            if roic >= wacc: return {'score': self._linear_interpolate(roic_percent, wacc * 100, 60, 7, 70), 'evaluation': 'ã€åˆæ ¼ãƒ©ã‚¤ãƒ³ã€‘'}
            if roic < wacc: return {'score': self._linear_interpolate(roic_percent, 0, 40, wacc * 100, 60), 'evaluation': 'ã€ä¾¡å€¤ç ´å£Šã€‘'}
        if roic < 0: return {'score': 20, 'evaluation': 'ã€æ·±åˆ»ãªå•é¡Œã€‘'}
        return {'score': 40, 'evaluation': 'ã€ä¾¡å€¤ç ´å£Šã€‘'}

    def _calculate_peg_score(self, peg_ratio: float | None) -> dict:
        if peg_ratio is None or peg_ratio < 0:
            score, evaluation = 0, "ã€æˆé•·éˆåŒ–ãƒ»èµ¤å­—ã€‘" if peg_ratio is not None else "---"
        elif peg_ratio <= 0.5: score, evaluation = 100, "ã€è¶…å‰²å®‰ãªæˆé•·æ ªã€‘"
        elif peg_ratio <= 1.0: score, evaluation = self._linear_interpolate(peg_ratio, 0.5, 100, 1.0, 70), "ã€å‰²å®‰ãªæˆé•·æ ªã€‘"
        elif peg_ratio <= 1.5: score, evaluation = self._linear_interpolate(peg_ratio, 1.0, 70, 1.5, 40), "ã€é©æ­£ä¾¡æ ¼ã€‘"
        elif peg_ratio < 2.0: score, evaluation = self._linear_interpolate(peg_ratio, 1.5, 40, 2.0, 0), "ã€ã‚„ã‚„å‰²é«˜ã€‘"
        else: score, evaluation = 0, "ã€å‰²é«˜ã€‘"
        return {'score': int(score), 'evaluation': evaluation}

    def _get_alternative_per(self, ticker_obj, info: dict) -> dict:
        trailing_pe = info.get('trailingPE')
        if trailing_pe is not None and trailing_pe > 0:
            logger.info(f"PERå–å¾—æ–¹æ³•1: yfinance.infoã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ (trailingPE: {trailing_pe:.2f})")
            return {'value': trailing_pe, 'note': None}
        current_price = info.get('regularMarketPrice')
        trailing_eps = info.get('trailingEps')
        if current_price is not None and trailing_eps is not None and trailing_eps > 0:
            calculated_per = current_price / trailing_eps
            logger.info(f"PERå–å¾—æ–¹æ³•2: æœ€æ–°æ ªä¾¡({current_price}) / æœ€æ–°EPS({trailing_eps}) ã§è¨ˆç®—ã—ã¾ã—ãŸ (PER: {calculated_per:.2f})")
            return {'value': calculated_per, 'note': None}
        try:
            financials = ticker_obj.financials
            history = ticker_obj.history(period="3y")
            if not financials.empty and 'Basic EPS' in financials.index and not history.empty:
                if hasattr(history.index.dtype, 'tz') and history.index.dtype.tz is not None:
                    history.index = history.index.tz_localize(None)
                eps_series = financials.loc['Basic EPS'].dropna()
                if len(eps_series) >= 1:
                    latest_settlement_date = eps_series.index[0]
                    latest_eps = eps_series.iloc[0]
                    price_on_settlement = history.asof(latest_settlement_date)['Close']
                    if pd.notna(price_on_settlement) and pd.notna(latest_eps) and latest_eps > 0:
                        calculated_per = price_on_settlement / latest_eps
                        date_str = latest_settlement_date.strftime('%Y-%m-%d')
                        note = f"æ³¨è¨˜: æ‰‹è¨ˆç®—PER ({date_str}æ™‚ç‚¹)ã‚’PERã¨ã—ã¦ä»£ç”¨"
                        logger.info(f"PERå–å¾—æ–¹æ³•3: ç›´è¿‘æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã§è¨ˆç®— ({price_on_settlement:.2f} / {latest_eps:.2f} = {calculated_per:.2f})")
                        return {'value': calculated_per, 'note': note}
                if len(eps_series) >= 2:
                    prev_settlement_date = eps_series.index[1]
                    prev_eps = eps_series.iloc[1]
                    price_on_settlement = history.asof(prev_settlement_date)['Close']
                    if pd.notna(price_on_settlement) and pd.notna(prev_eps) and prev_eps > 0:
                        calculated_per = price_on_settlement / prev_eps
                        date_str = prev_settlement_date.strftime('%Y-%m-%d')
                        note = f"æ³¨è¨˜: æ‰‹è¨ˆç®—PER ({date_str}æ™‚ç‚¹)ã‚’PERã¨ã—ã¦ä»£ç”¨"
                        logger.info(f"PERå–å¾—æ–¹æ³•4: 2æœŸå‰æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã§è¨ˆç®— ({price_on_settlement:.2f} / {prev_eps:.2f} = {calculated_per:.2f})")
                        return {'value': calculated_per, 'note': note}
        except Exception as e:
            logger.warning(f"ä»£æ›¿PERã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        logger.warning("å…¨ã¦ã®PERå–å¾—/è¨ˆç®—æ–¹æ³•ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        return {'value': None, 'note': None}

    def _calculate_scoring_indicators(self, all_fin_data: dict, yf_data: dict) -> dict:
        indicators = {'calc_warnings': [], 'formulas': {}, 'variables': {}}
        latest_bs_data = self.get_latest_financial_data(all_fin_data.get('è²¸å€Ÿå¯¾ç…§è¡¨', {}))
        latest_pl_data = self.get_latest_financial_data(all_fin_data.get('æç›Šè¨ˆç®—æ›¸', {}))
        market_cap, pe, rf_rate, mrp, trailing_eps = (yf_data.get(k) for k in ['marketCap', 'trailingPE', 'risk_free_rate', 'mkt_risk_premium', 'trailingEps'])
        beta = yf_data.get('beta')
        indicators['variables']['æ™‚ä¾¡ç·é¡'] = market_cap
        indicators['variables']['PER (å®Ÿç¸¾)'] = pe
        indicators['variables']['ãƒ™ãƒ¼ã‚¿å€¤'] = beta
        if beta is None:
            beta = 1.0
            indicators['calc_warnings'].append("æ³¨è¨˜: Î²å€¤ã®ä»£ã‚ã‚Šã«1.0ã§ä»£ç”¨")
        securities_keys = ['æœ‰ä¾¡è¨¼åˆ¸', 'æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸', 'ãã®ä»–ã®é‡‘èè³‡ç”£']
        securities = self.get_value(latest_bs_data, securities_keys, 'æœ‰ä¾¡è¨¼åˆ¸')
        if securities is not None and securities < 0:
            indicators['calc_warnings'].append("æ³¨è¨˜: æœ‰ä¾¡è¨¼åˆ¸ãŒãƒã‚¤ãƒŠã‚¹ã ã£ãŸãŸã‚0ã¨ã—ã¦è¨ˆç®—")
            securities = 0
        indicators['variables']['æœ‰ä¾¡è¨¼åˆ¸'] = securities
        if securities is None:
            securities = 0
            indicators['calc_warnings'].append("æ³¨è¨˜: æœ‰ä¾¡è¨¼åˆ¸ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚0ã¨ã—ã¦è¨ˆç®—")
        op_income = self.get_value(latest_pl_data, ['å–¶æ¥­åˆ©ç›Š'], 'å–¶æ¥­åˆ©ç›Š')
        op_income_source = 'å–¶æ¥­åˆ©ç›Š'
        if op_income is None:
            op_income = self.get_value(latest_pl_data, ['ç¨å¼•å‰åˆ©ç›Š', 'ç¨é‡‘ç­‰èª¿æ•´å‰å½“æœŸç´”åˆ©ç›Š'], 'ç¨å¼•å‰åˆ©ç›Š(ä»£æ›¿)')
            op_income_source = 'ç¨å¼•å‰åˆ©ç›Š'
        if op_income is None:
            op_income = self.get_value(latest_pl_data, ['å½“æœŸç´”åˆ©ç›Š', 'è¦ªä¼šç¤¾æ ªä¸»ã«å¸°å±ã™ã‚‹å½“æœŸç´”åˆ©ç›Š'], 'å½“æœŸç´”åˆ©ç›Š(ä»£æ›¿)')
            op_income_source = 'å½“æœŸç´”åˆ©ç›Š'
        indicators['roic_source_key'] = op_income_source
        if op_income_source != 'å–¶æ¥­åˆ©ç›Š' and op_income is not None:
            indicators['calc_warnings'].append(f"ä¿¡é ¼æ€§è­¦å‘Š: å–¶æ¥­åˆ©ç›Šã®ä»£ã‚ã‚Šã«ã€Œ{op_income_source}ã€ã‚’ä½¿ç”¨")
        indicators['variables'][f'NOPATè¨ˆç®—ç”¨åˆ©ç›Š ({op_income_source})'] = op_income
        net_assets = self.get_value(latest_bs_data, ['ç´”è³‡ç”£åˆè¨ˆ', 'ç´”è³‡ç”£'], 'ç´”è³‡ç”£')
        pretax_income = self.get_value(latest_pl_data, ['ç¨å¼•å‰åˆ©ç›Š', 'ç¨é‡‘ç­‰èª¿æ•´å‰å½“æœŸç´”åˆ©ç›Š'], 'ç¨å¼•å‰åˆ©ç›Š')
        corp_tax = self.get_value(latest_pl_data, ['æ³•äººç¨ç­‰', 'æ³•äººç¨ã€ä½æ°‘ç¨åŠã³äº‹æ¥­ç¨'], 'æ³•äººç¨ç­‰')
        keijo_rieki = self.get_value(latest_pl_data, ['çµŒå¸¸åˆ©ç›Š'], 'çµŒå¸¸åˆ©ç›Š')
        net_income = self.get_value(latest_pl_data, ['å½“æœŸç´”åˆ©ç›Š', 'è¦ªä¼šç¤¾æ ªä¸»ã«å¸°å±ã™ã‚‹å½“æœŸç´”åˆ©ç›Š'], 'å½“æœŸç´”åˆ©ç›Š')
        indicators['variables']['ç´”è³‡ç”£'] = net_assets
        indicators['variables']['çµŒå¸¸åˆ©ç›Š'] = keijo_rieki
        indicators['variables']['å½“æœŸç´”åˆ©ç›Š'] = net_income
        def check_reqs(reqs, names):
            missing = [name for req, name in zip(reqs, names) if req is None]
            return None if not missing else f"ä¸è¶³: {', '.join(missing)}"
        current_assets = self.get_value(latest_bs_data, ['æµå‹•è³‡ç”£åˆè¨ˆ', 'æµå‹•è³‡ç”£'], 'æµå‹•è³‡ç”£')
        total_liabilities = self.get_value(latest_bs_data, ['è² å‚µåˆè¨ˆ'], 'è² å‚µ')
        if total_liabilities is None:
            total_liabilities = self.get_value(latest_bs_data, ['è² å‚µ'], 'è² å‚µ')
            if total_liabilities is not None:
                indicators['calc_warnings'].append("æ³¨è¨˜: NCæ¯”ç‡è¨ˆç®—ã§ã€Œè² å‚µåˆè¨ˆã€ã®ä»£ã‚ã‚Šã«ã€Œè² å‚µã€ã§ä»£ç”¨")
        indicators['variables']['æµå‹•è³‡ç”£'] = current_assets
        indicators['variables']['è² å‚µåˆè¨ˆ'] = total_liabilities
        nc_ratio, nc_error = None, None
        nc_reqs, nc_names = [market_cap, current_assets, securities, total_liabilities], ["æ™‚ä¾¡ç·é¡", "æµå‹•è³‡ç”£", "æœ‰ä¾¡è¨¼åˆ¸", "è² å‚µåˆè¨ˆ"]
        nc_error = check_reqs(nc_reqs, nc_names)
        if not nc_error:
            if market_cap > 0:
                nc_ratio = (current_assets + (securities * 0.7) - total_liabilities) / (market_cap / 1_000_000)
                indicators['formulas']['ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡'] = f"({current_assets:,.0f} + {securities:,.0f}*0.7 - {total_liabilities:,.0f}) / {market_cap/1e6:,.0f}"
            else:
                nc_error = "æ™‚ä¾¡ç·é¡ãŒã‚¼ãƒ­ã§ã™"
        cnper_reqs, cnper_names = [pe, nc_ratio], ["PER", "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡"]
        cn_per, cnper_error = None, check_reqs(cnper_reqs, cnper_names)
        if not cnper_error:
            cn_per = pe * (1 - nc_ratio)
            indicators['formulas']['ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PER'] = f"{pe:.2f} * (1 - {nc_ratio:.2f})"
        tax_rate = corp_tax / pretax_income if all(v is not None for v in [corp_tax, pretax_income]) and pretax_income > 0 else 0.3062
        indicators['variables']['ç¨ç‡'] = tax_rate
        debt = self.get_value(latest_bs_data, ['æœ‰åˆ©å­è² å‚µåˆè¨ˆ', 'æœ‰åˆ©å­è² å‚µ'], 'æœ‰åˆ©å­è² å‚µ')
        net_debt = self.get_value(latest_bs_data, ['ç´”æœ‰åˆ©å­è² å‚µ'], 'ç´”æœ‰åˆ©å­è² å‚µ')
        cash = self.get_value(latest_bs_data, ['ç¾é‡‘', 'ç¾é‡‘åŠã³é é‡‘'], 'ç¾é‡‘åŒç­‰ç‰©')
        indicators['variables']['æœ‰åˆ©å­è² å‚µ'] = debt
        indicators['variables']['ç´”æœ‰åˆ©å­è² å‚µ'] = net_debt
        indicators['variables']['ç¾é‡‘åŒç­‰ç‰©'] = cash
        interest_expense = self.get_value(latest_pl_data, ['æ”¯æ‰•åˆ©æ¯', 'é‡‘èè²»ç”¨'], 'æ”¯æ‰•åˆ©æ¯')
        cost_of_equity = rf_rate + beta * mrp if all(v is not None for v in [beta, rf_rate, mrp]) else None
        indicators['variables']['æ ªä¸»è³‡æœ¬ã‚³ã‚¹ãƒˆ'] = cost_of_equity
        effective_debt_for_wacc = debt
        if debt is None and net_debt is not None and cash is not None:
            effective_debt_for_wacc = net_debt + cash
            if effective_debt_for_wacc < 0: effective_debt_for_wacc = 0
        cost_of_debt = interest_expense / effective_debt_for_wacc if all(v is not None for v in [interest_expense, effective_debt_for_wacc]) and effective_debt_for_wacc > 0 else 0.0
        indicators['variables']['è² å‚µã‚³ã‚¹ãƒˆ'] = cost_of_debt
        wacc_reqs, wacc_names = [cost_of_equity, market_cap, effective_debt_for_wacc], ["æ ªä¸»è³‡æœ¬ã‚³ã‚¹ãƒˆ", "æ™‚ä¾¡ç·é¡", "æœ‰åˆ©å­è² å‚µ(ã¾ãŸã¯ä»£ç”¨å€¤)"]
        wacc_error = check_reqs(wacc_reqs, wacc_names)
        wacc = None
        if not wacc_error:
            e, d_yen = market_cap, effective_debt_for_wacc * 1_000_000
            v = e + d_yen
            if v > 0:
                wacc = cost_of_equity * (e / v) + cost_of_debt * (1 - tax_rate) * (d_yen / v)
                indicators['formulas']['WACC'] = f"Ke {cost_of_equity:.2%} * (E/V {(e/v):.2%}) + Kd {cost_of_debt:.2%} * (1-T {tax_rate:.2%}) * (D/V {(d_yen/v):.2%})"
        roic, roic_error = None, None
        invested_capital_debt = debt
        if debt is None and net_debt is not None and cash is not None:
            invested_capital_debt = net_debt + cash
            indicators['calc_warnings'].append("æ³¨è¨˜: ROICè¨ˆç®—ã§ç´”æœ‰åˆ©å­è² å‚µã‚’ä»£ç”¨")
        roic_reqs, roic_names = [op_income, net_assets, invested_capital_debt], [op_income_source, "ç´”è³‡ç”£", "æœ‰åˆ©å­è² å‚µ(ã¾ãŸã¯ä»£ç”¨å€¤)"]
        roic_error = check_reqs(roic_reqs, roic_names)
        if not roic_error:
            invested_capital = net_assets + invested_capital_debt
            nopat = op_income * (1 - tax_rate)
            if invested_capital > 0:
                roic = nopat / invested_capital
                indicators['formulas']['ROIC'] = f"{nopat:,.0f} / {invested_capital:,.0f}"
        nc_score_dict = self._score_net_cash_ratio(nc_ratio)
        cn_per_score_dict = self._score_cn_per(cn_per, keijo_rieki, pe, trailing_eps)
        roic_score_dict = self._score_roic(roic, wacc)
        indicators['net_cash_ratio'] = {'value': nc_ratio, 'reason': nc_error, **nc_score_dict}
        indicators['cn_per'] = {'value': cn_per, 'reason': cnper_error, **cn_per_score_dict}
        indicators['roic'] = {'value': roic, 'reason': roic_error, **roic_score_dict}
        indicators['wacc'] = {'value': wacc, 'reason': wacc_error}
        return indicators

    def get_yfinance_statements(self, ticker_obj):
        statements = {
            "å¹´æ¬¡æç›Šè¨ˆç®—æ›¸": self.format_yfinance_df(ticker_obj.financials),
            "å››åŠæœŸæç›Šè¨ˆç®—æ›¸": self.format_yfinance_df(ticker_obj.quarterly_financials),
            "å¹´æ¬¡è²¸å€Ÿå¯¾ç…§è¡¨": self.format_yfinance_df(ticker_obj.balance_sheet),
            "å››åŠæœŸè²¸å€Ÿå¯¾ç…§è¡¨": self.format_yfinance_df(ticker_obj.quarterly_balance_sheet),
            "å¹´æ¬¡CFè¨ˆç®—æ›¸": self.format_yfinance_df(ticker_obj.cashflow),
            "å››åŠæœŸCFè¨ˆç®—æ›¸": self.format_yfinance_df(ticker_obj.quarterly_cashflow),
        }
        return statements

    def get_timeseries_financial_metrics(self, ticker_obj, info) -> pd.DataFrame:
        financials = ticker_obj.financials
        balance_sheet = ticker_obj.balance_sheet
        hist = ticker_obj.history(period="5y")
        dividends = ticker_obj.dividends
        if hasattr(hist.index.dtype, 'tz') and hist.index.dtype.tz is not None: hist.index = hist.index.tz_localize(None)
        if hasattr(dividends.index.dtype, 'tz') and dividends.index.dtype.tz is not None: dividends.index = dividends.index.tz_localize(None)
        if financials.empty:
            logger.warning(f"éŠ˜æŸ„ {info.get('shortName', '')}: yfinanceã®å¹´æ¬¡è²¡å‹™ãƒ‡ãƒ¼ã‚¿(financials)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            financials = pd.DataFrame(columns=[pd.Timestamp.now() - pd.DateOffset(years=i) for i in range(4)])
        if balance_sheet.empty:
            logger.warning(f"éŠ˜æŸ„ {info.get('shortName', '')}: yfinanceã®å¹´æ¬¡è²¸å€Ÿå¯¾ç…§è¡¨ãƒ‡ãƒ¼ã‚¿(balance_sheet)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            balance_sheet = pd.DataFrame(columns=financials.columns)
        equity_keys = ['Total Stockholder Equity', 'Stockholders Equity', 'Total Equity']
        assets_keys = ['Total Assets']
        shares_keys = ['Share Issued', 'Ordinary Shares Number', 'Basic Average Shares']
        revenue_keys = ['Total Revenue', 'Revenues', 'Total Sales']
        net_income_keys = ['Net Income', 'Net Income From Continuing Operations']
        eps_keys = ['Basic EPS']
        def find_yf_value(df, keys, col):
            if df.empty or col not in df.columns: return None
            for key in keys:
                if key in df.index: return df.loc[key, col]
            return None
        metrics = []
        annual_columns = financials.columns[:min(4, financials.shape[1])]
        logger.info(f"{info.get('shortName', '')}: {len(annual_columns)}æœŸåˆ†ã®å¹´æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
        for date_col in annual_columns:
            stockholder_equity = find_yf_value(balance_sheet, equity_keys, date_col)
            total_assets = find_yf_value(balance_sheet, assets_keys, date_col)
            net_income = find_yf_value(financials, net_income_keys, date_col)
            shares_outstanding = find_yf_value(balance_sheet, shares_keys, date_col)
            total_revenue = find_yf_value(financials, revenue_keys, date_col)
            price = hist.asof(date_col)['Close'] if not hist.empty else None
            eps = find_yf_value(financials, eps_keys, date_col)
            equity_ratio = (stockholder_equity / total_assets) * 100 if pd.notna(stockholder_equity) and pd.notna(total_assets) and total_assets > 0 else None
            annual_dividends = 0
            if not dividends.empty:
                dividends_in_year = dividends[dividends.index.year == date_col.year]
                if not dividends_in_year.empty: annual_dividends = dividends_in_year.sum()
            roe = (net_income / stockholder_equity) * 100 if pd.notna(net_income) and pd.notna(stockholder_equity) and stockholder_equity != 0 else None
            sps = total_revenue / shares_outstanding if pd.notna(total_revenue) and pd.notna(shares_outstanding) and shares_outstanding != 0 else None
            psr = price / sps if pd.notna(price) and pd.notna(sps) and sps != 0 else None
            per = price / eps if pd.notna(price) and pd.notna(eps) and eps != 0 else None
            bps = stockholder_equity / shares_outstanding if pd.notna(stockholder_equity) and pd.notna(shares_outstanding) and shares_outstanding != 0 else None
            pbr = price / bps if pd.notna(price) and pd.notna(bps) and bps != 0 else None
            div_yield = (annual_dividends / price) * 100 if pd.notna(price) and price > 0 else None
            metrics.append({
                'æ±ºç®—æ—¥': date_col.strftime('%Y-%m-%d'), 'å¹´åº¦': f"{date_col.year}å¹´åº¦", 'EPS (å††)': eps, 'PER (å€)': per, 'PBR (å€)': pbr,
                'PSR (å€)': psr, 'ROE (%)': roe, 'è‡ªå·±è³‡æœ¬æ¯”ç‡ (%)': equity_ratio, 'å¹´é–“1æ ªé…å½“ (å††)': annual_dividends, 'é…å½“åˆ©å›ã‚Š (%)': div_yield
            })
        latest_equity_ratio = None
        if not balance_sheet.empty and not balance_sheet.columns.empty:
            latest_bs_col_name = balance_sheet.columns[0]
            latest_equity = find_yf_value(balance_sheet, equity_keys, latest_bs_col_name)
            latest_assets = find_yf_value(balance_sheet, assets_keys, latest_bs_col_name)
            if pd.notna(latest_equity) and pd.notna(latest_assets) and latest_assets > 0:
                latest_equity_ratio = (latest_equity / latest_assets) * 100
        roe_info = info.get('returnOnEquity')
        latest_metrics = {
            'æ±ºç®—æ—¥': date.today().strftime('%Y-%m-%d'), 'å¹´åº¦': 'æœ€æ–°', 'EPS (å††)': info.get('trailingEps'), 'PER (å€)': info.get('trailingPE'),
            'PBR (å€)': info.get('priceToBook'), 'PSR (å€)': info.get('priceToSalesTrailing12Months'), 'ROE (%)': roe_info * 100 if roe_info else None,
            'è‡ªå·±è³‡æœ¬æ¯”ç‡ (%)': latest_equity_ratio, 'å¹´é–“1æ ªé…å½“ (å††)': info.get('trailingAnnualDividendRate'), 'é…å½“åˆ©å›ã‚Š (%)': info.get('trailingAnnualDividendYield') * 100 if info.get('trailingAnnualDividendYield') else None
        }
        metrics.append(latest_metrics)
        df = pd.DataFrame(metrics).set_index('æ±ºç®—æ—¥').sort_index(ascending=True)
        df['EPSæˆé•·ç‡ (å¯¾å‰å¹´æ¯”) (%)'] = df['EPS (å††)'].pct_change(fill_method=None) * 100
        return df.sort_index(ascending=False)

    def calculate_peg_ratios(self, ticker_obj, info: dict) -> dict:
        results = {
            'cagr_growth': {'value': None, 'growth': None, 'reason': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³', 'eps_points': [], 'start_eps': None, 'end_eps': None, 'years': 0},
            'single_year': {'value': None, 'growth': None, 'reason': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³'},
            'historical_pegs': {},
            'warnings': []
        }
        try:
            current_per = info.get('trailingPE')
            if not current_per:
                for key in results:
                    if key not in ['historical_pegs', 'warnings']:
                        results[key]['reason'] = 'ç¾åœ¨ã®PERãŒå–å¾—ã§ãã¾ã›ã‚“'
                return results
            financials = ticker_obj.financials
            if financials.empty or 'Basic EPS' not in financials.index:
                for key in results:
                    if key not in ['historical_pegs', 'warnings']:
                        results[key]['reason'] = 'EPSãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
                return results
            annual_eps_data = financials.loc['Basic EPS'].dropna().sort_index(ascending=False)
            if len(annual_eps_data) >= 2:
                latest_annual_eps, prev_annual_eps = annual_eps_data.iloc[0], annual_eps_data.iloc[1]
                if pd.notna(latest_annual_eps) and pd.notna(prev_annual_eps) and prev_annual_eps > 0:
                    growth = (latest_annual_eps - prev_annual_eps) / prev_annual_eps
                    results['single_year']['growth'] = growth
                    if growth > 0:
                        results['single_year']['value'] = current_per / (growth * 100)
                        results['single_year']['reason'] = None
                    else:
                        results['single_year']['reason'] = 'å˜å¹´æˆé•·ç‡ãŒãƒã‚¤ãƒŠã‚¹'
                else:
                    results['single_year']['reason'] = 'EPSãƒ‡ãƒ¼ã‚¿æ¬ æã¾ãŸã¯å‰æœŸãŒãƒã‚¤ãƒŠã‚¹'
            trailing_eps = info.get('trailingEps')
            if trailing_eps is not None:
                points = [trailing_eps] + annual_eps_data.tolist()
                valid_points = [p for p in points if pd.notna(p)]
                results['cagr_growth']['eps_points'] = valid_points
                if len(valid_points) >= 2:
                    start_eps = valid_points[-1]
                    end_eps = valid_points[0]
                    years = len(valid_points) - 1
                    results['cagr_growth']['start_eps'] = start_eps
                    results['cagr_growth']['end_eps'] = end_eps
                    results['cagr_growth']['years'] = years
                    if start_eps < 0 and end_eps > 0:
                        eps_improvement = end_eps - start_eps
                        results['cagr_growth']['growth'] = float('inf')
                        results['cagr_growth']['reason'] = f"{years}å¹´ã§EPSãŒ{eps_improvement:+.2f}æ”¹å–„"
                        results['cagr_growth']['value'] = None
                        results['warnings'].append('æ³¨è¨˜: èµ¤å­—ã‹ã‚‰é»’å­—ã«è»¢æ›ã—ãŸãŸã‚PEGã¯è¨ˆç®—ã§ãã¾ã›ã‚“ãŒã€EPSã®çµ¶å¯¾é¡ã¯æ”¹å–„ã—ã¦ã„ã¾ã™ã€‚')
                    elif start_eps > 0 and end_eps > 0:
                        cagr = (end_eps / start_eps)**(1/years) - 1
                        results['cagr_growth']['growth'] = cagr
                        if cagr > 0:
                            results['cagr_growth']['value'] = current_per / (cagr * 100)
                            results['cagr_growth']['reason'] = f'{years}å¹´é–“ã®CAGR'
                        else:
                            results['cagr_growth']['reason'] = f'{years}å¹´CAGRãŒãƒã‚¤ãƒŠã‚¹'
                    else:
                        results['cagr_growth']['reason'] = 'é–‹å§‹/çµ‚äº†EPSãŒãƒã‚¤ãƒŠã‚¹ã¾ãŸã¯ã‚¼ãƒ­ã®ãŸã‚è¨ˆç®—ä¸èƒ½'
                        if start_eps <= 0:
                            results['warnings'].append('æ³¨è¨˜: é–‹å§‹EPSãŒãƒã‚¤ãƒŠã‚¹ã¾ãŸã¯ã‚¼ãƒ­ã®ãŸã‚ã€CAGRãƒ™ãƒ¼ã‚¹ã®PEGã¯è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚')
                else:
                    results['cagr_growth']['reason'] = 'æœ‰åŠ¹ãªEPSãŒ2åœ°ç‚¹æœªæº€'
            history = ticker_obj.history(period="6y")
            if not history.empty and len(annual_eps_data) >= 2:
                if hasattr(history.index.dtype, 'tz') and history.index.dtype.tz is not None:
                    history.index = history.index.tz_localize(None)
                for i in range(len(annual_eps_data) - 1):
                    eps_curr = annual_eps_data.iloc[i]
                    eps_prev = annual_eps_data.iloc[i+1]
                    year_date = annual_eps_data.index[i]
                    if pd.notna(eps_curr) and pd.notna(eps_prev) and eps_prev > 0:
                        yoy_growth = (eps_curr - eps_prev) / eps_prev
                        if yoy_growth > 0:
                            price_at_fis_year = history.asof(year_date)['Close'] if not history.empty and not history.asof(year_date).empty else None
                            if price_at_fis_year:
                                historical_per = price_at_fis_year / eps_curr
                                peg = historical_per / (yoy_growth * 100)
                                results['historical_pegs'][f"{year_date.year}å¹´åº¦"] = peg
        except Exception as e:
            logger.error(f"PEGãƒ¬ã‚·ã‚ªè¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return results

    def _format_period(self, period_original: str) -> str:
        text = period_original.replace('/', '.')
        try:
            year, month = text.split('.')
            return f"{year}å¹´{int(month)}æœˆ"
        except (ValueError, IndexError):
            return period_original

    def get_shareholder_data(self, soup: BeautifulSoup) -> pd.DataFrame:
        shareholders_data = []
        yearly_div = soup.find('div', id='holder-yearly')
        if not yearly_div or not (table := yearly_div.find('table', class_='history-table')):
            return pd.DataFrame()
        headers = [th.get_text(strip=True) for th in table.find('thead').find_all('th')][1:]
        if tbody := table.find('tbody'):
            for row in tbody.find_all('tr'):
                cells = row.find_all('td')
                if not cells: continue
                shareholder_name = cells[0].get_text(strip=True)
                for i, cell in enumerate(cells[1:]):
                    period = self._format_period(headers[i])
                    cell_text = cell.get_text("\n", strip=True)
                    if cell_text == "-": continue
                    shares_match = re.search(r'([\d,]+)åƒæ ª', cell_text)
                    percent_match = re.search(r'([\d\.]+)%', cell_text)
                    shares = int(shares_match.group(1).replace(',', '')) * 1000 if shares_match else 0
                    percentage = float(percent_match.group(1)) if percent_match else 0.0
                    if shares > 0:
                        shareholders_data.append({'ä¼šè¨ˆæœŸ': period, 'æ ªä¸»å': shareholder_name, 'ä¿æœ‰æ ªå¼æ•° (æ ª)': shares, 'ä¿æœ‰å‰²åˆ (%)': percentage})
        df = pd.DataFrame(shareholders_data)
        if not df.empty:
            df['é †ä½'] = df.groupby('ä¼šè¨ˆæœŸ')['ä¿æœ‰å‰²åˆ (%)'].rank(method='first', ascending=False).astype(int)
        return df

    def get_governance_data(self, soup: BeautifulSoup) -> pd.DataFrame:
        governance_data = []
        header = soup.find('h2', string='å½¹å“¡ã®çŠ¶æ³')
        if not header: return pd.DataFrame()
        tab_container = header.find_next_sibling('div')
        if not tab_container: return pd.DataFrame()
        if tab_ul := tab_container.find('ul', class_='nav-tabs'):
            tabs = tab_ul.find_all('a')
            panes = tab_container.find('div', class_='tab-content').find_all('div', class_='tab-pane')
            for tab, pane in zip(tabs, panes):
                period = self._format_period(tab.get_text(strip=True))
                self._parse_officer_table(pane, period, governance_data)
        else:
            period = "æœ€æ–°"
            self._parse_officer_table(tab_container, period, governance_data)
        df = pd.DataFrame(governance_data)
        if not df.empty and 'ä¼šè¨ˆæœŸ' in df.columns and df['ä¼šè¨ˆæœŸ'].str.contains('å¹´').any():
            df['ä¼šè¨ˆæœŸ_dt'] = pd.to_datetime(df['ä¼šè¨ˆæœŸ'].str.replace('å¹´', '-').str.replace('æœˆ', ''), format='%Y-%m', errors='coerce')
            df = df.sort_values(by='ä¼šè¨ˆæœŸ_dt', ascending=False).drop(columns='ä¼šè¨ˆæœŸ_dt')
        return df

    def _parse_officer_table(self, container, period, data_list):
        officer_table = container.find('table', class_='officer__history-table')
        if not officer_table or not (tbody := officer_table.find('tbody')): return
        for row in tbody.find_all('tr'):
            cols = row.find_all('td')
            if len(cols) < 5: continue
            position = cols[0].get_text(strip=True)
            name_parts = cols[1].get_text(separator='|', strip=True).split('|')
            name = name_parts[0] if name_parts else ''
            birth_date = name_parts[1] if len(name_parts) > 1 else ''
            age = name_parts[2] if len(name_parts) > 2 else ''
            shares_text = cols[4].get_text(strip=True).replace(',', '')
            shares = int(shares_text) if shares_text.isdigit() else 0
            data_list.append({'ä¼šè¨ˆæœŸ': period, 'å½¹è·': position, 'æ°å': name, 'ç”Ÿå¹´æœˆæ—¥': birth_date, 'å¹´é½¢': age, 'å½¹å“¡ã¨ã—ã¦ã®æ‰€æœ‰æ ªå¼æ•°': shares})

    def get_shareholder_and_governance_data(self, ticker_code: str) -> dict:
        s_soup = self.get_html_soup(f"https://www.buffett-code.com/company/{ticker_code}/mainshareholder")
        g_soup = self.get_html_soup(f"https://www.buffett-code.com/company/{ticker_code}/governance")
        df_shareholders = self.get_shareholder_data(s_soup) if s_soup else pd.DataFrame()
        df_governance = self.get_governance_data(g_soup) if g_soup else pd.DataFrame()
        is_owner_executive = False
        if not df_governance.empty:
            df_governance['å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰æ ªå¼æ•°'] = 0
            df_governance['å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)'] = 0.0
        if not df_shareholders.empty and not df_governance.empty:
            df_shareholders['ç…§åˆå'] = df_shareholders['æ ªä¸»å'].str.replace(' ', '').str.replace('ã€€', '')
            if 'ä¼šè¨ˆæœŸ' in df_shareholders.columns and df_shareholders['ä¼šè¨ˆæœŸ'].str.contains('å¹´').any():
                df_shareholders['ä¼šè¨ˆæœŸ_dt'] = pd.to_datetime(df_shareholders['ä¼šè¨ˆæœŸ'].str.replace('å¹´', '-').str.replace('æœˆ', ''), format='%Y-%m', errors='coerce')
                latest_shares = df_shareholders.sort_values('ä¼šè¨ˆæœŸ_dt').drop_duplicates('ç…§åˆå', keep='last')
            else:
                latest_shares = df_shareholders.drop_duplicates('ç…§åˆå', keep='last')
            shareholder_map = latest_shares.set_index('ç…§åˆå')[['ä¿æœ‰æ ªå¼æ•° (æ ª)', 'ä¿æœ‰å‰²åˆ (%)']].apply(tuple, axis=1).to_dict()
            for index, row in df_governance.iterrows():
                governance_name_normalized = row['æ°å'].replace(' ', '').replace('ã€€', '')
                if governance_name_normalized in shareholder_map:
                    share_count, percentage = shareholder_map[governance_name_normalized]
                    df_governance.loc[index, 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰æ ªå¼æ•°'] = share_count
                    df_governance.loc[index, 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)'] = percentage
                    is_owner_executive = True
        return {"shareholders_df": df_shareholders, "governance_df": df_governance, "is_owner_executive": is_owner_executive}

    def perform_full_analysis(self, ticker_code: str, options: dict) -> dict:
        result = {'ticker_code': ticker_code, 'warnings': [], 'buffett_code_data': {}, 'timeseries_df': pd.DataFrame()}
        try:
            logger.info(f"--- éŠ˜æŸ„ {ticker_code} ã®åˆ†æã‚’é–‹å§‹ ---")
            if self.session is None:
                raise ValueError("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            info = None
            ticker_obj = None
            for attempt in range(3):
                try:
                    ticker_obj = yf.Ticker(f"{ticker_code}.T")
                    info = ticker_obj.info
                    if info and info.get('quoteType') is not None:
                        logger.info(f"éŠ˜æŸ„ {ticker_code} ã®æƒ…å ±å–å¾—ã«æˆåŠŸã—ã¾ã—ãŸã€‚ ({attempt + 1}å›ç›®)")
                        break
                except Exception as e:
                    logger.warning(f"éŠ˜æŸ„ {ticker_code} ã®æƒ…å ±å–å¾—ã«å¤±æ•— ({attempt + 1}/3å›ç›®): {e}")
                    if attempt < 2: time.sleep(5)
            if not info or info.get('quoteType') is None:
                raise ValueError("yfinanceã‹ã‚‰æœ‰åŠ¹ãªæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚(3å›è©¦è¡Œå¾Œ)")
            company_name = info.get('shortName') or info.get('longName') or f"éŠ˜æŸ„ {ticker_code}"
            result['company_name'] = company_name
            result['yf_info'] = info
            result['is_ipo_within_5_years'] = False
            listing_date_str = self.get_listing_date(ticker_code)
            if listing_date_str:
                try:
                    listing_date = datetime.strptime(listing_date_str, '%Yå¹´%mæœˆ%dæ—¥')
                    if (datetime.now() - listing_date) < pd.Timedelta(days=365.25 * 5):
                        result['is_ipo_within_5_years'] = True
                        logger.info(f"éŠ˜æŸ„ {ticker_code} ã¯ä¸Šå ´5å¹´ä»¥å†…ã®éŠ˜æŸ„ã§ã™ã€‚")
                except ValueError as e:
                    logger.warning(f"ä¸Šå ´å¹´æœˆæ—¥ '{listing_date_str}' ã®æ—¥ä»˜å½¢å¼ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            if info.get('trailingPE') is None or info.get('trailingPE') <= 0:
                logger.info(f"éŠ˜æŸ„ {ticker_code}: yfinanceã®trailingPEãŒä¸é©åˆ‡ãªãŸã‚ã€ä»£æ›¿PERã®è¨ˆç®—ã‚’è©¦ã¿ã¾ã™ã€‚")
                per_result = self._get_alternative_per(ticker_obj, info)
                if per_result['value'] is not None:
                    info['trailingPE'] = per_result['value']
                    logger.info(f"ä»£æ›¿PER ({per_result['value']:.2f}) ã‚’æ¡ç”¨ã—ã¾ã—ãŸã€‚")
                    if per_result['note']:
                        result['warnings'].append(per_result['note'])
                else:
                    logger.warning(f"éŠ˜æŸ„ {ticker_code}: ä»£æ›¿PERã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            for statement, path in {"è²¸å€Ÿå¯¾ç…§è¡¨": "bs", "æç›Šè¨ˆç®—æ›¸": "pl"}.items():
                url = f"https://www.buffett-code.com/company/{ticker_code}/financial/{path}"
                soup = self.get_html_soup(url)
                if soup:
                    all_data = self.extract_all_financial_data(soup)
                    if all_data:
                        result['buffett_code_data'][statement] = all_data
                    else:
                        logger.warning(f"Buffett-Codeã‹ã‚‰{statement}ã®ãƒ‡ãƒ¼ã‚¿è§£æã«å¤±æ•—ã€‚")
                        result['buffett_code_data'][statement] = {}
                        raise ValueError(f"ãƒãƒ•ã‚§ãƒƒãƒˆã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã®{statement}ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                else:
                    raise ValueError(f"ãƒãƒ•ã‚§ãƒƒãƒˆã‚³ãƒ¼ãƒ‰({url})ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            yf_data_for_calc = {**info, **options}
            result['scoring_indicators'] = self._calculate_scoring_indicators(result['buffett_code_data'], yf_data_for_calc)
            result['warnings'].extend(result['scoring_indicators'].pop('calc_warnings', []))
            peg_results = self.calculate_peg_ratios(ticker_obj, info)
            result['peg_analysis'] = peg_results
            if peg_results.get('warnings'):
                result['warnings'].extend(peg_results['warnings'])
            cagr_peg_value = peg_results['cagr_growth']['value']
            peg_score_dict = self._calculate_peg_score(cagr_peg_value)
            result['scoring_indicators']['peg'] = {'value': cagr_peg_value, 'reason': peg_results['cagr_growth']['reason'], **peg_score_dict}
            s_safety = result['scoring_indicators']['net_cash_ratio']['score']
            s_value = result['scoring_indicators']['cn_per']['score']
            s_quality = result['scoring_indicators']['roic']['score']
            s_growth = result['scoring_indicators']['peg']['score']
            result['strategy_scores'] = {}
            for name, weights in STRATEGY_WEIGHTS.items():
                weighted_score = (
                    s_safety * weights['safety'] +
                    s_value * weights['value'] +
                    s_quality * weights['quality'] +
                    s_growth * weights['growth']
                )
                result['strategy_scores'][name] = weighted_score
            result['final_average_score'] = result['strategy_scores']['âš–ï¸ ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆãƒãƒ©ãƒ³ã‚¹ï¼‰']
            ts_df = self.get_timeseries_financial_metrics(ticker_obj, info)
            if not ts_df.empty:
                peg_col_name = 'PEG (å®Ÿç¸¾)'
                peg_df = pd.DataFrame(peg_results['historical_pegs'].items(), columns=['å¹´åº¦', peg_col_name])
                ts_df = ts_df.reset_index().merge(peg_df, on='å¹´åº¦', how='left').set_index('æ±ºç®—æ—¥')
                latest_index = ts_df[ts_df['å¹´åº¦'] == 'æœ€æ–°'].index
                if not latest_index.empty:
                    ts_df.loc[latest_index, peg_col_name] = peg_results['single_year']['value']
            result['timeseries_df'] = ts_df
            result['yfinance_statements'] = self.get_yfinance_statements(ticker_obj)
            try:
                shareholder_data = self.get_shareholder_and_governance_data(ticker_code)
                result.update(shareholder_data)
                logger.info(f"éŠ˜æŸ„ {ticker_code} ã®å¤§æ ªä¸»ãƒ»å½¹å“¡æƒ…å ±ã®å–å¾—ã«æˆåŠŸã€‚")
            except Exception as e:
                logger.error(f"éŠ˜æŸ„ {ticker_code} ã®å¤§æ ªä¸»ãƒ»å½¹å“¡æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                result['warnings'].append("å¤§æ ªä¸»ãƒ»å½¹å“¡æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                result['shareholders_df'] = pd.DataFrame()
                result['governance_df'] = pd.DataFrame()
                result['is_owner_executive'] = False
        except Exception as e:
            logger.error(f"éŠ˜æŸ„ {ticker_code} ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            result['error'] = f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            if 'company_name' not in result:
                result['company_name'] = f"éŠ˜æŸ„ {ticker_code} (ã‚¨ãƒ©ãƒ¼)"
        return result

# ==============================================================================
# åˆ†æå®Ÿè¡Œé–¢æ•°
# ==============================================================================
def run_stock_analysis(ticker_input_str: str, options: dict):
    """
    æŒ‡å®šã•ã‚ŒãŸéŠ˜æŸ„ãƒªã‚¹ãƒˆæ–‡å­—åˆ—ã«åŸºã¥ã„ã¦åˆ†æã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™ã€‚
    """
    input_queries = [q.strip() for q in ticker_input_str.split(',') if q.strip()]
    if not input_queries:
        st.error("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã¾ãŸã¯ä¼šç¤¾åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return None

    search_handler = st.session_state.data_handler
    target_stocks = []
    not_found_queries = []
    with st.spinner("éŠ˜æŸ„ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™..."):
        for query in input_queries:
            stock_info = search_handler.get_ticker_info_from_query(query)
            if stock_info:
                target_stocks.append(stock_info)
            else:
                not_found_queries.append(query)

    unique_target_stocks = list({stock['code']: stock for stock in target_stocks}.values())

    if not_found_queries:
        st.warning(f"ä»¥ä¸‹ã®éŠ˜æŸ„ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {', '.join(not_found_queries)}")

    if not unique_target_stocks:
        st.error("åˆ†æå¯¾è±¡ã®éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

    st.success(f"åˆ†æå¯¾è±¡: {', '.join([s['code'] for s in unique_target_stocks])}")
    progress_bar = st.progress(0)
    progress_text = st.empty()
    all_results = {}
    data_handler = st.session_state.data_handler
    total_stocks = len(unique_target_stocks)

    data_handler._reset_session()
    for i, stock_info in enumerate(unique_target_stocks):
        if i > 0 and (i % 4 == 0 or data_handler.session is None):
            logger.info(f"å®šæœŸçš„ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒªã‚»ãƒƒãƒˆã‚’å®Ÿè¡Œ ({i}éŠ˜æŸ„ç›®)")
            data_handler._reset_session()

        progress_text.text(f"åˆ†æä¸­... ({i+1}/{total_stocks}ä»¶å®Œäº†): {stock_info.get('name', '')} ({stock_info['code']})")

        if data_handler.session is None:
            logger.error(f"éŠ˜æŸ„ {stock_info['code']} ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã«å¤±æ•—ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            display_key = f"{stock_info.get('name', stock_info['code'])} ({stock_info['code']})"
            all_results[display_key] = {
                'error': 'ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒˆãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã‹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚',
                'company_name': stock_info.get('name', stock_info['code']),
                'ticker_code': stock_info['code']
            }
            progress_bar.progress((i + 1) / total_stocks)
            continue

        code = stock_info['code']
        result = data_handler.perform_full_analysis(code, options)
        result['sector'] = stock_info.get('sector', 'æ¥­ç¨®ä¸æ˜')
        # â˜…è¿½åŠ : æ¥­ç¨®ã‚³ãƒ¼ãƒ‰ã‚‚çµæœã«å«ã‚ã‚‹
        result['sector_code'] = stock_info.get('sector_code')
        display_key = f"{result.get('company_name', code)} ({code})"
        all_results[display_key] = result
        progress_bar.progress((i + 1) / total_stocks)

    progress_text.empty()
    progress_bar.empty()
    return all_results

# ==============================================================================
# GUIè¡¨ç¤ºç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==============================================================================
def get_recommendation(score):
    if score is None: return "---", "è©•ä¾¡ä¸èƒ½"
    if score >= 90: return "â˜…â˜…â˜…â˜…â˜…", "ç¥ãƒ¬ãƒ™ãƒ«"
    if score >= 80: return "â˜…â˜…â˜…â˜…â˜†", "éå¸¸ã«æ¨å¥¨"
    if score >= 70: return "â˜…â˜…â˜…â˜†â˜†", "è‰¯ã„æŠ•è³‡å€™è£œ"
    if score >= 50: return "â˜…â˜…â˜†â˜†â˜†", "æ¤œè¨ã®ä¾¡å€¤ã‚ã‚Š"
    if score >= 30: return "â˜…â˜†â˜†â˜†â˜†", "æ³¨æ„æ·±ã„åˆ†æãŒå¿…è¦"
    return "â˜†â˜†â˜†â˜†â˜†", "æ¨å¥¨ã—ãªã„"

def get_peg_investor_commentary(peg_value: float | None) -> str:
    if peg_value is None or peg_value < 0: return "è©•ä¾¡ä¸èƒ½ï¼šPEGãƒ¬ã‚·ã‚ªãŒè¨ˆç®—ã§ããªã„ã‹ã€æˆé•·ç‡ãŒãƒã‚¤ãƒŠã‚¹ã§ã™ã€‚"
    if peg_value < 0.5: return "ğŸ’ **è¶…å‰²å®‰**<br><br>ãƒ”ãƒ¼ã‚¿ãƒ¼ãƒ»ãƒªãƒ³ãƒï¼š ã€ŒPERãŒæˆé•·ç‡ã®åŠåˆ†ã§ã‚ã‚Œã°ã€ãã‚Œã¯éå¸¸ã«æœ‰æœ›ãªæ˜ã‚Šå‡ºã—ç‰©ã ã€‚ã€ã¾ã•ã«å½¼ã®ç†æƒ³ã§ã‚ã‚Šã€å¤§ããªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ã‚’ç§˜ã‚ãŸã€ŒãŠå®éŠ˜æŸ„ã€ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚"
    if 0.5 <= peg_value < 1: return "âœ… **å‰²å®‰**<br><br>ã‚¸ãƒ ãƒ»ã‚¯ãƒ¬ã‚¤ãƒãƒ¼ï¼š ã€Œæˆ‘ã€…ãŒæ¢ã—ã¦ã„ã‚‹ã®ã¯ã“ã‚Œã ï¼ã€ã¨å«ã¶æ°´æº–ã§ã™ã€‚<br>ãƒ”ãƒ¼ã‚¿ãƒ¼ãƒ»ãƒªãƒ³ãƒï¼š ã“ã®é ˜åŸŸã«ã‚ã‚‹æ ªã‚’ã€Œãƒãƒ¼ã‚²ãƒ³ä¾¡æ ¼ã§ã‚ã‚‹å¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ã„ã‚‹ã€ã¨è©•ä¾¡ã—ã¾ã™ã€‚ä¸¡æ°ãŒæœ€ã‚‚å¥½ã‚€ã€é­…åŠ›çš„ãªæŠ•è³‡é ˜åŸŸã§ã™ã€‚"
    if peg_value == 1: return "âš–ï¸ **é©æ­£**<br><br>ãƒ”ãƒ¼ã‚¿ãƒ¼ãƒ»ãƒªãƒ³ãƒï¼š ã€Œå…¬æ­£ãªä¾¡æ ¼ãŒã¤ã„ã¦ã„ã‚‹ä¼æ¥­ã®PERã¯ã€ãã®æˆé•·ç‡ã«ç­‰ã—ã„ã€‚ã€ã“ã‚ŒãŒå½¼ã®å®šç¾©ã—ãŸã€Œé©æ­£ä¾¡æ ¼ã€ã®åŸºæº–ç‚¹ã€‚ã“ã“ã‹ã‚‰å‰²å®‰ã‹å‰²é«˜ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚"
    if 1 < peg_value < 2: return "ğŸ¤” **å‰²é«˜å‚¾å‘**<br><br>ã‚¸ãƒ ãƒ»ã‚¯ãƒ¬ã‚¤ãƒãƒ¼ï¼š ã€Œ2æœªæº€ã§ã‚ã‚Œã°è¨±å®¹ã§ãã‚‹ã€ã¨èªã‚‹ã€å½¼ã®æŸ”è»Ÿæ€§ãŒè¡¨ã‚Œã‚‹é ˜åŸŸã€‚ãƒªãƒ³ãƒæ°ãªã‚‰æ…é‡ã«ãªã‚Šã¾ã™ãŒã€ã‚¯ãƒ¬ã‚¤ãƒãƒ¼æ°ã¯ç´ æ™´ã‚‰ã—ã„ä¼æ¥­ã§ã‚ã‚Œã°ã€ã“ã®ç¨‹åº¦ã®ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã¯è¨±å®¹ç¯„å›²ã ã¨è€ƒãˆã¾ã™ã€‚"
    if peg_value >= 2: return "âŒ **å‰²é«˜**<br><br>ãƒ”ãƒ¼ã‚¿ãƒ¼ãƒ»ãƒªãƒ³ãƒï¼š ã€ŒPERãŒæˆé•·ç‡ã®2å€ã§ã‚ã‚Œã°éå¸¸ã«å±é™ºã ã€ã¨è­¦å‘Šã—ã¾ã™ã€‚<br>ã‚¸ãƒ ãƒ»ã‚¯ãƒ¬ã‚¤ãƒãƒ¼ï¼š ã€Œã©ã‚“ãªã«ãã®ä¼šç¤¾ãŒå¥½ãã§ã‚‚é«˜ã™ãã‚‹ï¼ˆtoo rich for our bloodï¼‰ã€ã¨ä¸€è¹´ã™ã‚‹æ°´æº–ã€‚ä¸¡æ°ãŒã€Œæ‰‹ã‚’å‡ºã™ã¹ãã§ã¯ãªã„ã€ã¨å£ã‚’æƒãˆã‚‹å±é™ºæ°´åŸŸã§ã™ã€‚"
    return "è©•ä¾¡ä¸èƒ½"

def get_kiyohara_commentary(net_cash_ratio, cn_per, net_income):
    nc_comment = "### æ¸…åŸå¼ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡ã®è©•ä¾¡\n\n"
    if net_cash_ratio is None: nc_comment += "è©•ä¾¡ä¸èƒ½ (ãƒ‡ãƒ¼ã‚¿ä¸è¶³)"
    elif net_cash_ratio >= 1.0: nc_comment += "ã€è¶…å®‰å…¨åœãƒ»é‰„å£ã€‘ğŸ”µ ä¼æ¥­ã®æ™‚ä¾¡ç·é¡ã‚’ä¸Šå›ã‚‹å®Ÿè³ªçš„ãªç¾é‡‘ã‚’ä¿æœ‰ã™ã‚‹æœ€é«˜ãƒ¬ãƒ™ãƒ«ã€‚ ç†è«–ä¸Šã¯ã€ä¼šç¤¾ã‚’ä¸¸ã”ã¨è²·åã—ã¦ã‚‚ãŠé‡£ã‚ŠãŒãã‚‹è¨ˆç®—ã«ãªã‚Šã¾ã™ã€‚å€’ç”£ãƒªã‚¹ã‚¯ã¯æ¥µã‚ã¦ä½ãã€ä¸‹å€¤ä¸å®‰ãŒéå¸¸ã«å°ã•ã„ã€Œé‰„å£ã®è²¡å‹™ã€ã¨è¨€ãˆã¾ã™ã€‚æ¸…åŸæ°ãŒã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®å¯¾è±¡ã¨ã—ãŸã®ã‚‚ã€ã“ã®100%ã‚’è¶…ãˆã‚‹ã‚ˆã†ãªè¶…å‰²å®‰éŠ˜æŸ„ã§ã—ãŸã€‚"
    elif net_cash_ratio >= 0.8: nc_comment += "ã€æ¥µã‚ã¦å®‰å…¨ã€‘ğŸŸ¢ æ™‚ä¾¡ç·é¡ã®å¤§éƒ¨åˆ†ãŒãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§è£ä»˜ã‘ã‚‰ã‚Œã¦ãŠã‚Šã€è²¡å‹™åŸºç›¤ã¯ç›¤çŸ³ã§ã™ã€‚æ ªä¾¡ãŒä¼æ¥­ã®å®Ÿè³ªçš„ãªä¾¡å€¤ã«å¯¾ã—ã¦å¤§å¹…ã«å‰²å®‰ã§ã‚ã‚‹å¯èƒ½æ€§ãŒéå¸¸ã«é«˜ã„æ°´æº–ã§ã™ã€‚M&Aã‚„å¤§è¦æ¨¡ãªæ ªä¸»é‚„å…ƒï¼ˆè‡ªç¤¾æ ªè²·ã„ã€å¢—é…ï¼‰ã®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚‚ç§˜ã‚ã¦ã„ã¾ã™ã€‚"
    elif net_cash_ratio >= 0.5: nc_comment += "ã€éå¸¸ã«å®‰å…¨ãƒ»å‰²å®‰ã€‘ğŸŸ¢ æ™‚ä¾¡ç·é¡ã®åŠåˆ†ä»¥ä¸Šã‚’ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå ã‚ã‚‹ã€éå¸¸ã«å®‰å…¨ãªæ°´æº–ã€‚ ä¸æ³ã‚„äºˆæœŸã›ã¬çµŒå–¶ç’°å¢ƒã®å¤‰åŒ–ã«å¯¾ã™ã‚‹è€æ€§ãŒæ¥µã‚ã¦é«˜ãã€å®‰å¿ƒã—ã¦é•·æœŸä¿æœ‰ã‚’æ¤œè¨ã§ãã‚‹è²¡å‹™å†…å®¹ã§ã™ã€‚å¤šãã®å„ªè‰¯ãªãƒãƒªãƒ¥ãƒ¼æ ªãŒã“ã®é ˜åŸŸã«å«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
    elif net_cash_ratio >= 0.2: nc_comment += "ã€å®‰å…¨åœã€‘ğŸŸ¡ ååˆ†ã«åšã„ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿æœ‰ã—ã¦ãŠã‚Šã€è²¡å‹™çš„ãªå®‰å®šæ„ŸãŒã‚ã‚Šã¾ã™ã€‚ ä¸€èˆ¬çš„ãªåŸºæº–ã§è¦‹ã‚Œã°ã€ååˆ†ã«è²¡å‹™å¥å…¨æ€§ãŒé«˜ã„ã¨è¨€ãˆã‚‹ãƒ¬ãƒ™ãƒ«ã§ã™ã€‚ã“ã®æ°´æº–ã§ã‚‚ã€å‰²å®‰ã¨åˆ¤æ–­ã§ãã‚‹éŠ˜æŸ„ã¯å¤šãå­˜åœ¨ã—ã¾ã™ã€‚"
    elif net_cash_ratio >= 0.1: nc_comment += "ã€ã‚„ã‚„æ³¨æ„ã€‘ğŸŸ  ä¸€å®šã®ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚ã‚Šã¾ã™ãŒã€ä¸Šè¨˜ã®æ°´æº–ã¨æ¯”è¼ƒã™ã‚‹ã¨è²¡å‹™çš„ãªä½™è£•ã¯å°‘ãªããªã£ã¦ãã¾ã™ã€‚æœ‰åˆ©å­è² å‚µã®é¡ã‚„ã€æœ¬æ¥­ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼å‰µå‡ºåŠ›ãªã©ã€ä»–ã®è²¡å‹™æŒ‡æ¨™ã¨åˆã‚ã›ã¦æ…é‡ã«è©•ä¾¡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
    elif net_cash_ratio >= 0.01: nc_comment += "ã€è¦æ³¨æ„ã€‘ğŸ”´ ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã»ã¨ã‚“ã©ãªã„çŠ¶æ…‹ã§ã™ã€‚ã™ãã«å±é™ºã¨ã„ã†ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€è²¡å‹™çš„ãªãƒãƒƒãƒ•ã‚¡ãƒ¼ã¯å°ã•ã„ã¨è¨€ãˆã¾ã™ã€‚ç‰¹ã«ã€æœ‰åˆ©å­è² å‚µã®å¤šã„ä¼æ¥­ã¯ã€é‡‘åˆ©ã®ä¸Šæ˜‡å±€é¢ã«æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚æˆé•·ã®ãŸã‚ã®å…ˆè¡ŒæŠ•è³‡ã§ä¸€æ™‚çš„ã«ã“ã®æ°´æº–ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™ã€‚"
    else: nc_comment += "ã€è¦è­¦æˆ’ã€‘ğŸš¨ å®Ÿè³ªçš„ãªç¾é‡‘ã‚ˆã‚Šã‚‚æœ‰åˆ©å­è² å‚µãŒå¤šã„ã€Œãƒãƒƒãƒˆãƒ‡ãƒƒãƒˆï¼ˆç´”è² å‚µï¼‰ã€ã®çŠ¶æ…‹ã€‚ æ¸…åŸæ°ã®ã‚ˆã†ãªãƒãƒªãƒ¥ãƒ¼æŠ•è³‡å®¶ãŒå¥½ã‚€è²¡å‹™çŠ¶æ³ã¨ã¯è¨€ãˆã¾ã›ã‚“ã€‚ãŸã ã—ã€é‡‘èæ©Ÿé–¢ã‚„ã€æˆé•·ã®ãŸã‚ã«è²¡å‹™ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’ç©æ¥µçš„ã«æ´»ç”¨ã™ã‚‹ä¼æ¥­ï¼ˆä¸å‹•ç”£æ¥­ã€ITé–¢é€£ãªã©ï¼‰ã§ã¯ä¸€èˆ¬çš„ã§ã™ã€‚äº‹æ¥­å†…å®¹ã‚„æˆé•·æ€§ã‚’ç²¾æŸ»ã—ã€è² å‚µã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã¦ã„ã‚‹ã‹ã‚’å³ã—ãè¦‹æ¥µã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
    cn_per_comment = "\n\n<br><br>\n\n### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PERã®è©•ä¾¡\n\n"
    if net_income is not None and net_income <= 0:
        if cn_per is not None and cn_per < 0:
            cn_per_comment += "ã€è¦æ³¨æ„æ ªã€‘ğŸ§ ã€Œä¾¡å€¤ã®ç½ ã€ã®å¯èƒ½æ€§ã‚ã‚Šã€‚äº‹æ¥­ãŒåˆ©ç›Šã‚’ç”Ÿã¿å‡ºã›ã¦ã„ãªã„èµ¤å­—çŠ¶æ…‹ã€‚ã©ã‚Œã ã‘è³‡ç”£ã‚’æŒã£ã¦ã„ã¦ã‚‚ã€äº‹æ¥­æ´»å‹•ã§ãã‚Œã‚’é£Ÿã„ã¤ã¶ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚èµ¤å­—ãŒä¸€æ™‚çš„ãªã‚‚ã®ã‹ã€æ§‹é€ çš„ãªã‚‚ã®ã‹ã€ãã®åŸå› ã‚’è©³ã—ãèª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        else:
            cn_per_comment += "ã€èµ¤å­—ä¼æ¥­ãƒ»åˆ†ææ³¨æ„ã€‘äº‹æ¥­ãŒåˆ©ç›Šã‚’ç”Ÿã¿å‡ºã›ã¦ã„ãªã„èµ¤å­—çŠ¶æ…‹ã§ã™ã€‚è²¡å‹™å¥å…¨æ€§ï¼ˆãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡ï¼‰ã¯é‡è¦ã§ã™ãŒã€äº‹æ¥­ãã®ã‚‚ã®ã®å°†æ¥æ€§ã‚’æ…é‡ã«è©•ä¾¡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
    elif cn_per is None:
        cn_per_comment += "è©•ä¾¡ä¸èƒ½ (PERç­‰ã®ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚è¨ˆç®—ä¸å¯)"
    elif cn_per < 0:
        cn_per_comment += "ã€ç©¶æ¥µã®å‰²å®‰æ ªã€‘ğŸ¤‘ ãŠå®æ ªã®å¯èƒ½æ€§å¤§ã€‚äº‹æ¥­ä¾¡å€¤ãŒãƒã‚¤ãƒŠã‚¹ï¼ˆæ™‚ä¾¡ç·é¡ < ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ãªã®ã«åˆ©ç›Šã¯å‡ºã¦ã„ã‚‹çŠ¶æ…‹ã€‚ãªãœå¸‚å ´ãŒã“ã‚Œã»ã©ã¾ã§ã«è©•ä¾¡ã—ã¦ã„ãªã„ã®ã‹ã€éš ã‚ŒãŸãƒªã‚¹ã‚¯ãŒãªã„ã‹ã‚’ç²¾æŸ»ã™ã‚‹ä¾¡å€¤ãŒéå¸¸ã«é«˜ã„ã§ã™ã€‚"
    elif 0 <= cn_per < 2:
        cn_per_comment += "ã€ç¾é‡‘ã‚ˆã‚Šå®‰ã„ä¼šç¤¾ã€‘ğŸ¤¯ ğŸ’\n\n> ã€Œæ™‚ä¾¡ç·é¡ã‹ã‚‰ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¼•ã„ãŸäº‹æ¥­ä¾¡å€¤ãŒã€ç´”åˆ©ç›Šã®1ï½2å¹´åˆ†ã—ã‹ãªã„ã¨ã„ã†ã“ã¨ã€‚ã“ã‚Œã¯ã‚‚ã†ã€ã€ã»ã¼ã‚¿ãƒ€ã€ã§ä¼šç¤¾ãŒæ‰‹ã«å…¥ã‚‹ã®ã«ç­‰ã—ã„ã€‚ãªãœå¸‚å ´ãŒã“ã“ã¾ã§è¦‹æ¨ã¦ã¦ã„ã‚‹ã®ã‹ã€ä½•ã‹ç‰¹åˆ¥ãªæ‚ªææ–™ãŒãªã„ã‹å¾¹åº•çš„ã«èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€ãã†ã§ãªã‘ã‚Œã°ã€ã‚ã‚Šãˆãªã„å®‰å€¤ã€ã ã€‚ã“ã†ã„ã†ä¼šç¤¾ã¯ã€èª°ã‹ãŒãã®ä¾¡å€¤ã«æ°—ã¥ã‘ã°ã€æ ªä¾¡ã¯ç°¡å˜ã«2å€ã€3å€ã«ãªã‚‹å¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ã„ã‚‹ã€\n\n**è©•ä¾¡:** æœ€å¤§é™ã®è²·ã„è©•ä¾¡ã€‚ãŸã ã—ã€ç•°å¸¸ãªå®‰ã•ã®è£ã«éš ã‚ŒãŸãƒªã‚¹ã‚¯ï¼ˆè¨´è¨Ÿã€å¶ç™ºå‚µå‹™ãªã©ï¼‰ãŒãªã„ã‹ã¯æ…é‡ã«ç¢ºèªã™ã‚‹ã€ã¨ã„ã†ã‚¹ã‚¿ãƒ³ã‚¹ã§ã—ã‚‡ã† ğŸ¤”ã€‚"
    elif 2 <= cn_per < 4:
        cn_per_comment += "ã€ç§ã®æŠ•è³‡ã®ã©çœŸã‚“ä¸­ã€‘ğŸ¯ ğŸ’ª\n\n> ã€Œå®Ÿè³ªPERãŒ4å€ä»¥ä¸‹ã€‚ã“ã‚ŒãŒç§ã®æŠ•è³‡ã®ã©çœŸã‚“ä¸­ã ã€‚ ã“ã®æ°´æº–ã§ã‚ã‚Œã°ã€å¤šå°‘ã®æˆé•·æ€§ã®éˆåŒ–ã‚„æ¥­ç¸¾ã®ãƒ–ãƒ¬ãªã©æ„ã«ä»‹ã•ãªã„ã€‚äº‹æ¥­ä¾¡å€¤ãŒã“ã‚Œã ã‘å®‰ã‘ã‚Œã°ã€ä¸‹å€¤ãƒªã‚¹ã‚¯ã¯é™å®šçš„ã€‚å¸‚å ´å‚åŠ è€…ã®å¤šããŒãã®ä¾¡å€¤ã«æ°—ã¥ã„ã¦ã„ãªã„ã ã‘ã§ã€æ”¾ã£ã¦ãŠã‘ã°ã„ãšã‚Œè©•ä¾¡ã•ã‚Œã‚‹ã€‚ã“ã†ã„ã†éŠ˜æŸ„ã“ãã€å®‰å¿ƒã—ã¦å¤§ããªé‡‘é¡ã‚’æŠ•ã˜ã‚‰ã‚Œã‚‹ã€\n\n**è©•ä¾¡:** æœ€ã‚‚ä¿¡é ¼ã‚’ç½®ãã€ç©æ¥µçš„ã«æŠ•è³‡å¯¾è±¡ã¨ã™ã‚‹ã€Œã‚³ã‚¢ãƒ»ã‚¾ãƒ¼ãƒ³ã€ã§ã™ã€‚å½¼ã®æŠ•è³‡è¡“ã®ç¥é«„ãŒã“ã®ä¾¡æ ¼å¸¯ã«ã‚ã‚‹ã¨è¨€ãˆã¾ã™ âœ…ã€‚"
    elif 4 <= cn_per < 7:
        cn_per_comment += "ã€ã¾ã‚ã€æ‚ªããªã„æ°´æº–ã€‘ğŸ‘ ğŸ™‚\n\n> ã€Œå®Ÿè³ªPERãŒ5å€ã€6å€ã­â€¦ã€‚ã¾ã‚ã€æ‚ªããªã„æ°´æº–ã ã€‚æ™®é€šã®ãƒãƒªãƒ¥ãƒ¼æŠ•è³‡å®¶ãªã‚‰å–œã‚“ã§è²·ã†ã ã‚ã†ã€‚ãŸã ã€ç§ã«è¨€ã‚ã›ã‚Œã°ã€ã“ã“ã‹ã‚‰å…ˆã¯ã€æ™®é€šã«å®‰ã„ä¼šç¤¾ã€ã§ã‚ã£ã¦ã€é©šãã»ã©ã®å®‰ã•ã§ã¯ãªã„ã€‚ä»–ã«è²·ã†ã¹ãã‚‚ã®ãŒãªã‘ã‚Œã°æ¤œè¨ã™ã‚‹ãŒã€èƒ¸ã‚’å¼µã£ã¦ã€ã“ã‚Œã¯è²·ã„ã ã€ã¨æ–­è¨€ã™ã‚‹ã«ã¯å°‘ã—ç‰©è¶³ã‚Šãªã•ã‚’æ„Ÿã˜ã‚‹ã€\n\n**è©•ä¾¡:** è¨±å®¹ç¯„å›²ã§ã¯ã‚ã‚‹ã‚‚ã®ã®ã€æœ€é«˜ã®æŠ•è³‡å¯¾è±¡ã¨ã¯è¦‹ãªã—ã¾ã›ã‚“ã€‚ã‚ˆã‚Šå‰²å®‰ãªéŠ˜æŸ„ãŒã‚ã‚Œã°ã€ãã¡ã‚‰ã‚’å„ªå…ˆã™ã‚‹ã§ã—ã‚‡ã†ã€‚"
    elif 7 <= cn_per < 10:
        cn_per_comment += "ã€æ™®é€šã®ä¼šç¤¾ã€‘ğŸ˜ ğŸ“ˆ\n\n> ã€Œå®Ÿè³ªPERãŒ10å€è¿‘ãã«ãªã£ã¦ãã‚‹ã¨ã€ã‚‚ã¯ã‚„å‰²å®‰ã¨ã¯è¨€ãˆãªã„ã€‚ã€æ™®é€šã®ä¼šç¤¾ã€ã®å€¤æ®µã ã€‚ ã“ã®æ°´æº–ã®æ ªã‚’è²·ã†ã®ã§ã‚ã‚Œã°ã€ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¾¡å€¤ã ã‘ã§ã¯ä¸ååˆ†ã§ã€å°†æ¥ã®æˆé•·æ€§ãŒã©ã‚Œã ã‘ã‚ã‚‹ã‹ã¨ã„ã†è­°è«–ãŒä¸å¯æ¬ ã«ãªã‚‹ã€‚ã—ã‹ã—ã€ç§ã«ã¯ãã®æœªæ¥ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹èƒ½åŠ›ã¯ãªã„ã€\n\n**è©•ä¾¡:** å½¼ã®å¾—æ„ã¨ã™ã‚‹ã€Œè³‡ç”£ä¾¡å€¤ã€ã‚’æ‹ ã‚Šæ‰€ã¨ã—ãŸæŠ•è³‡ã‚¹ã‚¿ã‚¤ãƒ«ã‹ã‚‰ã¯å¤–ã‚Œå§‹ã‚ã¾ã™ã€‚æˆé•·æ€§ã®è©•ä¾¡ã¨ã„ã†ä¸ç¢ºå®Ÿãªé ˜åŸŸã«å…¥ã‚‹ãŸã‚ã€æŠ•è³‡å¯¾è±¡ã¨ã—ã¦ã®é­…åŠ›ã¯å¤§ããè–„ã‚Œã¾ã™ ğŸ¤·â€â™‚ï¸ã€‚"
    elif 10 <= cn_per < 15:
        cn_per_comment += "ã€ç§ã«ã¯å‰²é«˜ã«æ€ãˆã‚‹ã€‘ğŸ¤¨ ğŸ‘\n\n> ã€Œå¤šãã®å¸‚å ´å‚åŠ è€…ãŒã€é©æ­£æ°´æº–ã ã€ã¨è¨€ã†ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ç§ã«ã¯ã‚‚ã†å‰²é«˜ã«æ€ãˆã‚‹ã€‚ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å·®ã—å¼•ã„ãŸäº‹æ¥­ä¾¡å€¤ã§ã™ã‚‰ã€åˆ©ç›Šã®10å¹´ä»¥ä¸Šåˆ†ã‚’æ‰•ã†ã¨ã„ã†ã“ã¨ã€‚ãã‚Œã ã‘ã®ä¾¡å€¤ãŒã‚ã‚‹ã¨ã„ã†ãªã‚‰ã€ã‚ˆã»ã©ç´ æ™´ã‚‰ã—ã„æˆé•·ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¨ã€ãã‚Œã‚’å®Ÿç¾ã§ãã‚‹çµŒå–¶é™£ãŒå¿…è¦ã«ãªã‚‹ã€‚ç§ã«ã¯åšæ‰“ã«ã—ã‹è¦‹ãˆãªã„ ğŸ²ã€\n\n**è©•ä¾¡:** æ˜ç¢ºã«ã€Œå‰²é«˜ã€ã¨åˆ¤æ–­ã—ã€é€šå¸¸ã¯æŠ•è³‡å¯¾è±¡ã¨ã—ã¾ã›ã‚“ã€‚"
    else:
        cn_per_comment += "ã€è«–å¤–ã€‚ãƒãƒ–ãƒ«ä»¥å¤–ã®ä½•ç‰©ã§ã‚‚ãªã„ã€‘âŒ ğŸ¤®\n\n> ã€Œå®Ÿè³ªPERãŒ20å€ã ã®30å€ã ã®ã¨ã„ã†ã®ã¯ã€ã¯ã£ãã‚Šè¨€ã£ã¦è«–å¤–ã ã€‚ ã©ã‚Œã ã‘è¼ã‹ã—ã„æœªæ¥ã‚’èªã‚‰ã‚Œã‚ˆã†ã¨ã€ãã‚Œã¯å˜ãªã‚‹å¤¢ç‰©èªã€‚æ ªä¾¡ã¯æœŸå¾…ã ã‘ã§å½¢æˆã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã†ã„ã†ä¼šç¤¾ãŒãã®å¾Œã©ã†ãªã‚‹ã‹ã€ç§ã¯ä½•åº¦ã‚‚è¦‹ã¦ããŸã€‚ã“ã‚Œã¯æŠ•è³‡ã§ã¯ãªãæŠ•æ©Ÿã§ã‚ã‚Šã€ãƒãƒ–ãƒ«ä»¥å¤–ã®ä½•ç‰©ã§ã‚‚ãªã„ ğŸ’¥ã€‚ã‚¢ãƒŠãƒªã‚¹ãƒˆãŒå…¨å“¡ã§å¼·æ°—ãªæ¨è–¦ã‚’ã—ã¦ã„ãŸã‚‰ã€ã‚€ã—ã‚ç©ºå£²ã‚Šã‚’æ¤œè¨ã™ã‚‹ãã‚‰ã„ã ã€\n\n**è©•ä¾¡:** æŠ•è³‡å¯¾è±¡ã¨ã—ã¦å…¨ãè€ƒãˆãªã„æ°´æº–ã§ã™ã€‚ã‚€ã—ã‚å¸‚å ´ã®éç†±ã‚’ç¤ºã™ã‚µã‚¤ãƒ³ã¨æ‰ãˆã€è­¦æˆ’ã‚’å¼·ã‚ã‚‹ã§ã—ã‚‡ã†ã€‚"
    return nc_comment + cn_per_comment

# ==============================================================================
# --- Streamlit App Main ---
# ==============================================================================
st.set_page_config(page_title="çµ±åˆå‹ ä¼æ¥­ä¾¡å€¤åˆ†æãƒ„ãƒ¼ãƒ«", layout="wide")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
if 'data_handler' not in st.session_state:
    st.session_state.data_handler = IntegratedDataHandler()
if 'results' not in st.session_state:
    st.session_state.results = None
if 'rf_rate' not in st.session_state:
    st.session_state.rf_rate = 0.01
if 'rf_rate_manual' not in st.session_state:
    st.session_state.rf_rate_manual = st.session_state.rf_rate
if 'rf_rate_fetched' not in st.session_state:
    st.session_state.rf_rate_fetched = False
# â˜…ä¿®æ­£1: ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ç©ºã«ã™ã‚‹
if 'ticker_input_value' not in st.session_state:
    st.session_state.ticker_input_value = ""


# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼UI ---
st.sidebar.title("åˆ†æè¨­å®š")

# --- ã‚·ãƒ³ãƒ—ãƒ«æ¤œç´¢ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
st.sidebar.subheader("éŠ˜æŸ„æ¤œç´¢ï¼ˆã‚·ãƒ³ãƒ—ãƒ«æ¤œç´¢ï¼‰")
ticker_input = st.sidebar.text_area(
    "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ or ä¼šç¤¾å (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)",
    value=st.session_state.ticker_input_value,
    key="ticker_input_widget"
)
analyze_button = st.sidebar.button("åˆ†æå®Ÿè¡Œ")

st.sidebar.markdown("---")

# --- AIé¡ä¼¼éŠ˜æŸ„æ¤œç´¢ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
st.sidebar.subheader("AIé¡ä¼¼éŠ˜æŸ„æ¤œç´¢")
ai_search_query = st.sidebar.text_input(
    "å¯¾è±¡ä¼æ¥­ (ã‚³ãƒ¼ãƒ‰ or ä¼šç¤¾å):",
    placeholder="ä¾‹: 7203 or ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š",
    key="ai_search_input"
)
ai_search_button = st.sidebar.button("é¡ä¼¼éŠ˜æŸ„æ¤œç´¢")

st.sidebar.markdown("---")

# --- è©³ç´°è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
st.sidebar.subheader("è©³ç´°è¨­å®š")
if not st.session_state.rf_rate_fetched:
    with st.spinner("æœ€æ–°ã®ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—ä¸­..."):
        rate = st.session_state.data_handler.get_risk_free_rate()
        if rate is not None:
            st.session_state.rf_rate = rate
            st.session_state.rf_rate_manual = rate
            st.success(f"ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆã‚’è‡ªå‹•å–å¾—ã—ã¾ã—ãŸ: {rate:.4f}")
    st.session_state.rf_rate_fetched = True

st.session_state.rf_rate_manual = st.sidebar.number_input(
    "ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆ(Rf)", value=st.session_state.rf_rate_manual, format="%.4f",
    help="æ—¥æœ¬ã®10å¹´å›½å‚µåˆ©å›ã‚Šã‚’åŸºæº–ã¨ã—ã¾ã™ã€‚è‡ªå‹•å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã¯æ‰‹å‹•ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
)
st.session_state.rf_rate = st.session_state.rf_rate_manual
mrp = st.sidebar.number_input("ãƒãƒ¼ã‚±ãƒƒãƒˆãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ (MRP)", value=0.06, format="%.2f")

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("çµ±åˆå‹ ä¼æ¥­ä¾¡å€¤åˆ†æãƒ„ãƒ¼ãƒ«")
st.caption(f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
options = {'risk_free_rate': st.session_state.rf_rate, 'mkt_risk_premium': mrp}

# AIé¡ä¼¼éŠ˜æŸ„æ¤œç´¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†
if ai_search_button:
    if not ai_search_query:
        st.sidebar.error("å¯¾è±¡ä¼æ¥­ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        search_handler = st.session_state.data_handler
        stock_info = search_handler.get_ticker_info_from_query(ai_search_query)

        if stock_info is None:
            st.sidebar.error(f"ã€Œ{ai_search_query}ã€ã«ä¸€è‡´ã™ã‚‹éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            target_code = stock_info['code']
            target_name = stock_info['name']
            target_sector = stock_info.get('sector')
            
            candidate_list_str = None
            status_message = f"ä¼æ¥­ã€Œ{target_name} ({target_code})ã€ã®é¡ä¼¼éŠ˜æŸ„ã‚’AIãŒæ¤œç´¢ä¸­..."

            # äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if target_sector and pd.notna(target_sector) and not search_handler.stock_list_df.empty:
                status_message = f"ã€Œ{target_sector}ã€æ¥­ç¨®å†…ã§é¡ä¼¼éŠ˜æŸ„ã‚’AIãŒæ¤œç´¢ä¸­..."
                candidate_df = search_handler.stock_list_df[
                    (search_handler.stock_list_df['sector'] == target_sector) &
                    (search_handler.stock_list_df['code'] != target_code)
                ]
                if not candidate_df.empty:
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«å€™è£œãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆæœ€å¤§100ä»¶ï¼‰
                    candidate_list = [f"- {row['name']} ({row['code']})" for index, row in candidate_df.head(100).iterrows()]
                    candidate_list_str = "\n".join(candidate_list)
            
            similar_tickers = ""
            with st.status(status_message, expanded=True) as status:
                try:
                    st.write("ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ã—ã¦ã„ã¾ã™...")
                    model = genai.GenerativeModel("gemini-1.5-flash-latest")
                    time.sleep(1)

                    st.write(f"ğŸ“ {target_name} ({target_code})ç”¨ã®é«˜åº¦ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
                    prompt = generate_prompt(target_code, candidate_list_str)
                    time.sleep(1)

                    st.write("â³ AIãŒé¡ä¼¼éŠ˜æŸ„ã‚’åˆ†æä¸­ã§ã™... (ã“ã‚Œã«ã¯æ•°åç§’ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")
                    response = model.generate_content(prompt)

                    st.write("âš™ï¸ å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢ã—ã¦ã„ã¾ã™...")
                    # â˜…ä¿®æ­£: æ•°å­—ã€ã‚«ãƒ³ãƒã€å¤§æ–‡å­—ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆä»¥å¤–ã‚’å‰Šé™¤
                    cleaned_text = re.sub(r'[^0-9,A-Z]', '', response.text.upper())
                    similar_tickers = ",".join(filter(None, cleaned_text.split(',')))
                    time.sleep(1)

                    if similar_tickers:
                        status.update(label="âœ… AIæ¤œç´¢å®Œäº†ï¼", state="complete", expanded=False)
                    else:
                        status.update(label="âš ï¸ AIãŒé¡ä¼¼éŠ˜æŸ„ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚", state="error", expanded=True)
                        st.warning("AIã‹ã‚‰é¡ä¼¼éŠ˜æŸ„ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

                except Exception as e:
                    status.update(label="âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", state="error", expanded=True)
                    st.error(f"AIæ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            if similar_tickers:
                # â˜…ä¿®æ­£2: æ¤œç´¢å…ƒã®éŠ˜æŸ„ã‚’ãƒªã‚¹ãƒˆã®å…ˆé ­ã«è¿½åŠ 
                final_ticker_list = f"{target_code},{similar_tickers}"
                st.session_state.ticker_input_value = final_ticker_list
                st.success(f"AIãŒæŠ½å‡ºã—ãŸéŠ˜æŸ„ãƒªã‚¹ãƒˆã§åˆ†æã‚’é–‹å§‹ã—ã¾ã™: {final_ticker_list}")
                time.sleep(1)
                results = run_stock_analysis(final_ticker_list, options)
                if results:
                    st.session_state.results = results
                    st.rerun()

# åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†
if analyze_button:
    st.session_state.ticker_input_value = ticker_input
    results = run_stock_analysis(ticker_input, options)
    if results:
        st.session_state.results = results

# --- çµæœè¡¨ç¤º ---
if st.session_state.results:
    all_results = st.session_state.results
    st.header("å€‹åˆ¥éŠ˜æŸ„ã‚µãƒãƒªãƒ¼")
    strategy_options = list(STRATEGY_WEIGHTS.keys())
    selected_strategy = st.radio("è¡¨ç¤ºæˆ¦ç•¥ã®åˆ‡ã‚Šæ›¿ãˆ:", strategy_options, horizontal=True, key='result_view_strategy')
    sorted_results = sorted(all_results.items(), key=lambda item: item[1].get('strategy_scores', {}).get(selected_strategy, -1), reverse=True)

    for display_key, result in sorted_results:
        ticker_code = result.get('ticker_code')
        if 'error' in result:
            with st.expander(f"â–¼ {display_key} - åˆ†æã‚¨ãƒ©ãƒ¼", expanded=True):
                st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\nè©³ç´°: {result['error']}")
            continue

        score = result.get('strategy_scores', {}).get(selected_strategy)
        stars_text, _ = get_recommendation(score)
        score_color = "#28a745" if score is not None and score >= 70 else "#ffc107" if score is not None and score >= 40 else "#dc3545"
        score_text = f"{score:.1f}" if score is not None else "N/A"

        st.markdown(f"<hr style='border: 2px solid {score_color};'>", unsafe_allow_html=True)
        col1, col2, col3 = st.columns([0.55, 0.3, 0.15])
        with col1:
            market_cap = result.get('yf_info', {}).get('marketCap')
            is_ipo_within_5_years = result.get('is_ipo_within_5_years', False)
            ipo_badge = f"<span style='display:inline-block; vertical-align:middle; padding:3px 8px; font-size:13px; font-weight:bold; color:white; background-color:#dc3545; border-radius:12px; margin-left:10px;'>ä¸Šå ´5å¹´ä»¥å†…</span>" if is_ipo_within_5_years else ""
            small_cap_badge = ""
            if market_cap and market_cap <= 10_000_000_000:
                small_cap_badge = f"<span style='display:inline-block; vertical-align:middle; padding:3px 8px; font-size:13px; font-weight:bold; color:white; background-color:#007bff; border-radius:12px; margin-left:10px;'>å°å‹æ ª</span>"
            
            # â˜…è¿½åŠ : ã‚·ã‚¯ãƒªã‚«ãƒ«éŠ˜æŸ„ãƒãƒƒã‚¸ã®ç”Ÿæˆ
            cyclical_badge = ""
            sector_code = result.get('sector_code')
            if sector_code and sector_code in CYCLICAL_SECTOR_CODES:
                 cyclical_badge = f"<span style='display:inline-block; vertical-align:middle; padding:3px 8px; font-size:13px; font-weight:bold; color:white; background-color:#6f42c1; border-radius:12px; margin-left:10px;'>ã‚·ã‚¯ãƒªã‚«ãƒ«éŠ˜æŸ„</span>"

            kabutan_link = ""
            if ticker_code:
                kabutan_url = f"https://kabutan.jp/stock/?code={ticker_code}"
                kabutan_link = f"<a href='{kabutan_url}' target='_blank' title='æ ªæ¢ã§æ ªä¾¡ã‚’ç¢ºèª' style='text-decoration:none; margin-left:10px; font-size:20px; vertical-align:middle;'>ğŸ”—</a>"
            is_owner_exec = result.get('is_owner_executive', False)
            owner_badge = f"<span style='display:inline-block; vertical-align:middle; padding:3px 8px; font-size:13px; font-weight:bold; color:white; background-color:#28a745; border-radius:12px; margin-left:10px;'>å¤§æ ªä¸»å½¹å“¡</span>" if is_owner_exec else ""
            sector = result.get('sector', '')
            sector_span = f"<span style='font-size:16px; color:grey; font-weight:normal; margin-left:10px;'>({sector})</span>" if sector and pd.notna(sector) else ""
            
            # â˜…ä¿®æ­£: ãƒãƒƒã‚¸è¡¨ç¤ºã‚’è¿½åŠ 
            st.markdown(f"### {display_key} {kabutan_link} {ipo_badge} {small_cap_badge} {owner_badge} {cyclical_badge} {sector_span}", unsafe_allow_html=True)
        with col2:
            info = result.get('yf_info', {})
            price, change, prev_close = info.get('regularMarketPrice'), info.get('regularMarketChange'), info.get('regularMarketPreviousClose')
            change_pct = (price - prev_close) / prev_close if all(isinstance(x, (int, float)) for x in [price, prev_close]) and prev_close > 0 else info.get('regularMarketChangePercent')
            if all(isinstance(x, (int, float)) for x in [price, change, change_pct]):
                st.metric(label="ç¾åœ¨æ ªä¾¡", value=f"{price:,.0f} å††", delta=f"å‰æ—¥æ¯” {change:+.2f}å†† ({change_pct:+.2%})")
        with col3:
            st.write("")
            st.write("")
            indicators = result.get('scoring_indicators', {})
            def format_for_copy(data):
                val = data.get('value')
                return f"{val:.2f} ({data.get('evaluation', '')})" if val is not None else "N/A"
            change_pct_text = f"({change_pct:+.2%})" if isinstance(change_pct, (int, float)) else ""
            price_text = f"æ ªä¾¡: {price:,.0f}å†† (å‰æ—¥æ¯” {change:+.2f}å††, {change_pct_text})" if all(isinstance(x, (int, float)) for x in [price, change]) else ""
            market_cap_val = result.get('yf_info', {}).get('marketCap')
            market_cap_text = ""
            if market_cap_val:
                if market_cap_val >= 1_000_000_000_000:
                    market_cap_text = f"æ™‚ä¾¡ç·é¡: {market_cap_val / 1_000_000_000_000:,.2f} å…†å††"
                else:
                    market_cap_text = f"æ™‚ä¾¡ç·é¡: {market_cap_val / 100_000_000:,.2f} å„„å††"
            features = []
            if market_cap_val and market_cap_val <= 10_000_000_000:
                features.append("å°å‹æ ª")
            if result.get('is_owner_executive', False):
                features.append("å¤§æ ªä¸»å½¹å“¡")
            if result.get('is_ipo_within_5_years', False):
                features.append("ä¸Šå ´5å¹´ä»¥å†…")
            if sector_code and sector_code in CYCLICAL_SECTOR_CODES:
                features.append("ã‚·ã‚¯ãƒªã‚«ãƒ«éŠ˜æŸ„")

            features_text = f"ç‰¹å¾´: {', '.join(features)}" if features else ""
            owner_info_text = ""
            df_g = result.get('governance_df')
            if result.get('is_owner_executive', False) and df_g is not None and not df_g.empty and 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)' in df_g.columns:
                owners = df_g[df_g['å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)'] > 0]
                if not owners.empty:
                    top_owner = owners.loc[owners['å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)'].idxmax()]
                    owner_name = top_owner.get('æ°å', 'ä¸æ˜')
                    owner_ratio = top_owner.get('å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)', 0)
                    owner_info_text = f"ç­†é ­ã‚ªãƒ¼ãƒŠãƒ¼çµŒå–¶è€…: {owner_name} ({owner_ratio:.2f}%)"
            copy_text = f"â–  {display_key}\n{price_text}"
            if market_cap_text: copy_text += f"\n{market_cap_text}"
            if features_text: copy_text += f"\n{features_text}"
            if owner_info_text: copy_text += f"\n{owner_info_text}"
            copy_text += (f"\n\nç·åˆã‚¹ã‚³ã‚¢ ({selected_strategy}): {score_text}ç‚¹ {stars_text}\n"
                          f"--------------------\nPEGãƒ¬ã‚·ã‚ª (CAGR): {format_for_copy(indicators.get('peg',{}))}\n"
                          f"ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡: {format_for_copy(indicators.get('net_cash_ratio',{}))}\n"
                          f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PER: {format_for_copy(indicators.get('cn_per',{}))}\n"
                          f"ROIC: {format_for_copy(indicators.get('roic',{}))}")
            create_copy_button(copy_text, "ğŸ“‹ çµæœã‚’ã‚³ãƒ”ãƒ¼", key=f"copy_{display_key.replace(' ','_')}")
        st.markdown(f"#### ç·åˆã‚¹ã‚³ã‚¢ ({selected_strategy}): <span style='font-size:28px; font-weight:bold; color:{score_color};'>{score_text}ç‚¹</span> <span style='font-size:32px;'>{stars_text}</span>", unsafe_allow_html=True)
        if result.get('warnings'): st.info(f"{'; '.join(list(set(result.get('warnings',[]))))}ã€‚")
        with st.container():
            cols = st.columns(4)
            def show_metric(col, title, subtitle, data, warnings):
                with col:
                    note = ""
                    if title == "PEGãƒ¬ã‚·ã‚ª (CAGR)" and any("PEG" in w for w in warnings): note = " *"
                    if title in ["ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PER"] and any(k in w for w in warnings for k in ["NCæ¯”ç‡", "è² å‚µ", "æœ‰ä¾¡åˆ¸"]): note = " *"
                    if title == "ROIC" and any("ROIC" in w for w in warnings): note = " *"
                    val, score = data.get('value'), data.get('score', 0)
                    val_str = f"{val:.2f}" if val is not None else "N/A"
                    color = "#28a745" if score >= 70 else "#ffc107" if score >= 40 else "#dc3545"
                    st.markdown(f"<div style='text-align:center;'><p style='font-size:14px; color:#555; font-weight:bold; margin-bottom:0;'>{title}{note}</p><p style='font-size:11px; color:#777; margin-bottom:5px; margin-top:-2px;'>{subtitle}</p></div>", unsafe_allow_html=True)
                    st.markdown(f"<p style='font-size:28px; color:{color}; font-weight:bold; text-align:center; margin:0;'>{val_str}</p>", unsafe_allow_html=True)
                    st.markdown(f"<p style='text-align:center; font-weight:bold; font-size:14px;'>ã‚¹ã‚³ã‚¢: <span style='color:{color};'>{score:.1f}ç‚¹</span></p>", unsafe_allow_html=True)
                    if val is None: st.markdown(f"<p style='text-align:center; font-size:12px; color:red;'>({data.get('reason', 'è¨ˆç®—ä¸èƒ½')})</p>", unsafe_allow_html=True)
                    else: st.markdown(f"<p style='text-align:center; font-size:12px; color:#777;'>{data.get('evaluation', '---')}</p>", unsafe_allow_html=True)
            show_metric(cols[0], "PEGãƒ¬ã‚·ã‚ª (CAGR)", "æˆé•·æ€§ã‚’è€ƒæ…®ã—ãŸæ ªä¾¡ã®å‰²å®‰æ€§", indicators.get('peg', {}), result.get('warnings', []))
            show_metric(cols[1], "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡", "ç¾é‡‘ã‚’è€ƒæ…®ã—ãŸå‰²å®‰åº¦", indicators.get('net_cash_ratio', {}), result.get('warnings', []))
            show_metric(cols[2], "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PER", "äº‹æ¥­ä¾¡å€¤ã®å‰²å®‰åº¦", indicators.get('cn_per', {}), result.get('warnings', []))
            show_metric(cols[3], "ROIC", "åç›Šæ€§ãƒ»è³‡æœ¬åŠ¹ç‡", indicators.get('roic', {}), result.get('warnings', []))
            with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹"):
                tab_titles = [
                    "æ™‚ç³»åˆ—æŒ‡æ¨™", "å¤§æ ªä¸»ãƒ»å½¹å“¡", "PEGãƒ¬ã‚·ã‚ª (CAGR) è¨ˆç®—", "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡è¨ˆç®—", "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PERè¨ˆç®—", "ROICè¨ˆç®—", "WACCè¨ˆç®—",
                    "PEGãƒ¬ã‚·ã‚ªã‚³ãƒ¡ãƒ³ãƒˆ", "å°‚é–€å®¶ã‚³ãƒ¡ãƒ³ãƒˆ", "è²¡å‹™è«¸è¡¨(ãƒãƒ•ã‚§ãƒƒãƒˆã‚³ãƒ¼ãƒ‰)", "ãƒ¤ãƒ•ãƒ¼ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹è²¡å‹™"
                ]
                tabs = st.tabs(tab_titles)
                with tabs[0]:
                    ts_df = result.get('timeseries_df')
                    if ts_df is not None and not ts_df.empty:
                        display_columns = ['å¹´åº¦', 'EPS (å††)', 'EPSæˆé•·ç‡ (å¯¾å‰å¹´æ¯”) (%)', 'PER (å€)', 'PBR (å€)', 'PEG (å®Ÿç¸¾)', 'PSR (å€)', 'ROE (%)', 'è‡ªå·±è³‡æœ¬æ¯”ç‡ (%)', 'å¹´é–“1æ ªé…å½“ (å††)', 'é…å½“åˆ©å›ã‚Š (%)']
                        df_to_display = ts_df.copy().reset_index()
                        existing_cols = [col for col in display_columns if col in df_to_display.columns]
                        df_to_display = df_to_display[['æ±ºç®—æ—¥'] + existing_cols]
                        numeric_cols = {col: "{:.2f}" for col in df_to_display.select_dtypes(include=np.number).columns}
                        st.dataframe(df_to_display.style.format(numeric_cols, na_rep="-"))
                    else:
                        st.warning("æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                with tabs[1]:
                    st.subheader(f"å¤§æ ªä¸»ãƒ»å½¹å“¡æƒ…å ± ({ticker_code})")
                    df_s = result.get('shareholders_df')
                    df_g = result.get('governance_df')
                    is_owner_executive = result.get('is_owner_executive', False)
                    if df_s is None and df_g is None:
                        st.warning(f"{ticker_code} ã®å¤§æ ªä¸»ãƒ»å½¹å“¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ãŸã‹ã€æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        if is_owner_executive:
                            st.success("âœ… **æ³¨ç›®:** å½¹å“¡ã«å¤§æ ªä¸»ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼ï¼ˆå½¹å“¡ãƒªã‚¹ãƒˆå†…ã§ç·‘è‰²ã®å¤ªå­—ã§è¡¨ç¤ºï¼‰", icon="â­")
                        tab1_sh, tab2_gov = st.tabs(["å¤§æ ªä¸»ãƒªã‚¹ãƒˆ", "å½¹å“¡ãƒªã‚¹ãƒˆ"])
                        with tab1_sh:
                            st.subheader(f"å¤§æ ªä¸»ãƒªã‚¹ãƒˆ")
                            if df_s is not None and not df_s.empty:
                                s_periods = df_s['ä¼šè¨ˆæœŸ'].unique()
                                s_selected_period = st.selectbox('ä¼šè¨ˆæœŸã‚’é¸æŠ:', options=s_periods, key=f"s_period_{ticker_code}")
                                s_display_df = df_s.loc[df_s['ä¼šè¨ˆæœŸ'] == s_selected_period, ['é †ä½', 'æ ªä¸»å', 'ä¿æœ‰å‰²åˆ (%)', 'ä¿æœ‰æ ªå¼æ•° (æ ª)']]
                                st.dataframe(s_display_df.style.format({'ä¿æœ‰æ ªå¼æ•° (æ ª)': '{:,.0f}','ä¿æœ‰å‰²åˆ (%)': '{:.2f}%'}), use_container_width=True, hide_index=True)
                                st.download_button("ğŸ“‹ å…¨æœŸé–“ã®[å¤§æ ªä¸»]ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_s.to_csv(index=False).encode('utf-8-sig'), f"shareholders_{ticker_code}.csv", 'text/csv', use_container_width=True, key=f"dl_s_{ticker_code}")
                            else:
                                st.warning("å¤§æ ªä¸»æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", icon="âš ï¸")
                        with tab2_gov:
                            st.subheader(f"å½¹å“¡ãƒªã‚¹ãƒˆ")
                            if df_g is not None and not df_g.empty:
                                def highlight_owner_executive(row):
                                    is_owner = row.get('å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰æ ªå¼æ•°', 0) > 0
                                    return ['color: #008000; font-weight: bold;'] * len(row) if is_owner else [''] * len(row)
                                g_display_df = df_g.copy()
                                if 'ä¼šè¨ˆæœŸ_dt' in g_display_df.columns:
                                    latest_period_row = df_g.loc[df_g['ä¼šè¨ˆæœŸ_dt'].idxmax()]
                                    latest_period = latest_period_row['ä¼šè¨ˆæœŸ']
                                    st.info(f"æœ€æ–°ã®å½¹å“¡æƒ…å ±ï¼ˆ{latest_period}æ™‚ç‚¹ï¼‰ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
                                    g_display_df = g_display_df.loc[g_display_df['ä¼šè¨ˆæœŸ'] == latest_period]
                                display_columns = ['å½¹è·', 'æ°å', 'ç”Ÿå¹´æœˆæ—¥', 'å¹´é½¢', 'å½¹å“¡ã¨ã—ã¦ã®æ‰€æœ‰æ ªå¼æ•°', 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰æ ªå¼æ•°', 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)']
                                display_columns = [col for col in display_columns if col in g_display_df.columns]
                                g_display_df = g_display_df[display_columns]
                                st.dataframe(
                                    g_display_df.style.format({
                                        'å½¹å“¡ã¨ã—ã¦ã®æ‰€æœ‰æ ªå¼æ•°': '{:,.0f}', 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰æ ªå¼æ•°': '{:,.0f}', 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)': '{:.2f}%'
                                    }).apply(highlight_owner_executive, axis=1),
                                    use_container_width=True, hide_index=True)
                                st.download_button("ğŸ“‹ å…¨æœŸé–“ã®[å½¹å“¡]ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_g.to_csv(index=False).encode('utf-8-sig'), f"governance_{ticker_code}.csv", 'text/csv', use_container_width=True, key=f"dl_g_{ticker_code}")
                            else:
                                st.warning("å½¹å“¡æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", icon="âš ï¸")
                with tabs[2]:
                    st.subheader("PEGãƒ¬ã‚·ã‚ª (CAGR) ã®è¨ˆç®—éç¨‹")
                    peg_analysis = result.get('peg_analysis', {})
                    peg_data = peg_analysis.get('cagr_growth', {})
                    peg_warnings = peg_analysis.get('warnings')
                    if peg_warnings: st.info(" ".join(list(set(peg_warnings))))
                    st.markdown(f"**è¨ˆç®—å¼:** `PER / (EPSã®CAGR * 100)`")
                    per_val = indicators.get('variables', {}).get('PER (å®Ÿç¸¾)')
                    if peg_data.get('value') is not None and isinstance(per_val, (int, float)):
                        st.text(f"PER {per_val:.2f} / (CAGR {peg_data.get('growth', 0)*100:.2f} %) = {peg_data.get('value'):.2f}")
                        st.markdown(f"**CAGR ({peg_data.get('years', 'N/A')}å¹´) è¨ˆç®—:** `(æœ€çµ‚EPS / åˆæœŸEPS) ** (1 / å¹´æ•°) - 1`")
                        if all(isinstance(x, (int, float)) for x in [peg_data.get('end_eps'), peg_data.get('start_eps'), peg_data.get('years')]) and peg_data.get('years', 0) > 0:
                            st.text(f"({peg_data['end_eps']:.2f} / {peg_data['start_eps']:.2f}) ** (1 / {peg_data['years']}) - 1 = {peg_data.get('growth', 0):.4f}")
                    else: st.error(f"è¨ˆç®—ä¸èƒ½ã€‚ç†ç”±: {peg_data.get('reason', 'ä¸æ˜')}")
                    st.markdown("**è¨ˆç®—ã«ä½¿ç”¨ã—ãŸEPSãƒ‡ãƒ¼ã‚¿ (æ–°ã—ã„é †):**")
                    eps_points = peg_data.get('eps_points', [])
                    if eps_points: st.text(str([f"{p:.2f}" if isinstance(p, (int, float)) else "N/A" for p in eps_points]))
                    else: st.warning('EPSãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚')
                with tabs[3]:
                    st.subheader("æ¸…åŸå¼ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡ã®è¨ˆç®—éç¨‹")
                    nc_warnings = [w for w in result.get('warnings', []) if any(k in w for k in ["NCæ¯”ç‡", "ç´”æœ‰åˆ©å­è² å‚µ", "æœ‰ä¾¡è¨¼åˆ¸", "è² å‚µ"])]
                    if nc_warnings: st.info(" ".join(list(set(nc_warnings))))
                    st.markdown(f"**è¨ˆç®—å¼:** `(æµå‹•è³‡ç”£ + æœ‰ä¾¡è¨¼åˆ¸*0.7 - è² å‚µåˆè¨ˆ) / æ™‚ä¾¡ç·é¡`")
                    formula = indicators.get('formulas', {}).get('ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡', indicators.get('net_cash_ratio', {}).get('reason'))
                    st.text(formula)
                    st.json({k: f"{v:,.0f} ç™¾ä¸‡å††" if isinstance(v, (int, float)) else "N/A" for k, v in {
                        "æµå‹•è³‡ç”£": indicators.get('variables', {}).get('æµå‹•è³‡ç”£'), "æœ‰ä¾¡è¨¼åˆ¸": indicators.get('variables', {}).get('æœ‰ä¾¡è¨¼åˆ¸'),
                        "è² å‚µåˆè¨ˆ": indicators.get('variables', {}).get('è² å‚µåˆè¨ˆ'),
                        "æ™‚ä¾¡ç·é¡": indicators.get('variables', {}).get('æ™‚ä¾¡ç·é¡', 0)/1e6 if isinstance(indicators.get('variables', {}).get('æ™‚ä¾¡ç·é¡'), (int, float)) else None
                    }.items()})
                with tabs[4]:
                    st.subheader("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PERã®è¨ˆç®—éç¨‹")
                    st.markdown(f"**è¨ˆç®—å¼:** `å®Ÿç¸¾PER * (1 - ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡)`")
                    formula = indicators.get('formulas', {}).get('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«PER', indicators.get('cn_per', {}).get('reason'))
                    st.text(formula)
                    per_val = indicators.get('variables', {}).get('PER (å®Ÿç¸¾)')
                    nc_ratio_val = indicators.get('net_cash_ratio', {}).get('value')
                    st.json({
                        "å®Ÿç¸¾PER": f"{per_val:.2f} å€" if isinstance(per_val, (int, float)) else "N/A",
                        "ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡": f"{nc_ratio_val:.2f}" if isinstance(nc_ratio_val, (int, float)) else f"N/A ({indicators.get('net_cash_ratio', {}).get('reason')})"
                    })
                with tabs[5]:
                    st.subheader("ROICã®è¨ˆç®—éç¨‹")
                    if roic_warnings := [w for w in result.get('warnings', []) if "ROIC" in w]: st.info(" ".join(list(set(roic_warnings))))
                    st.markdown(f"**è¨ˆç®—å¼:** `NOPAT (ç¨å¼•å¾Œå–¶æ¥­åˆ©ç›Š) / æŠ•ä¸‹è³‡æœ¬ (ç´”è³‡ç”£ + æœ‰åˆ©å­è² å‚µ)`")
                    formula = indicators.get('formulas', {}).get('ROIC', indicators.get('roic', {}).get('reason'))
                    st.text(formula)
                    def format_value(v, is_curr=True, is_pct=False):
                        if isinstance(v, (int, float)): return f"{v:.2%}" if is_pct else f"{v:,.0f} ç™¾ä¸‡å††" if is_curr else f"{v}"
                        return "N/A"
                    roic_vars = {
                        "NOPATè¨ˆç®—ç”¨åˆ©ç›Š": format_value(indicators.get('variables', {}).get(f"NOPATè¨ˆç®—ç”¨åˆ©ç›Š ({indicators.get('roic_source_key', '')})")),
                        "ç¨ç‡": format_value(indicators.get('variables', {}).get('ç¨ç‡'), is_pct=True),
                        "ç´”è³‡ç”£": format_value(indicators.get('variables', {}).get('ç´”è³‡ç”£')),
                    }
                    debt_val = indicators.get('variables', {}).get('æœ‰åˆ©å­è² å‚µ')
                    if debt_val is not None: roic_vars["æœ‰åˆ©å­è² å‚µ"] = format_value(debt_val)
                    else: roic_vars["ç´”æœ‰åˆ©å­è² å‚µ(ä»£ç”¨)"] = format_value(indicators.get('variables', {}).get('ç´”æœ‰åˆ©å­è² å‚µ'))
                    st.json(roic_vars)
                with tabs[6]:
                    st.subheader("WACC (åŠ é‡å¹³å‡è³‡æœ¬ã‚³ã‚¹ãƒˆ) ã®è¨ˆç®—éç¨‹")
                    if wacc_warnings := [w for w in result.get('warnings', []) if "Î²å€¤" in w]: st.info(" ".join(list(set(wacc_warnings))))
                    st.markdown(f"**è¨ˆç®—å¼:** `æ ªä¸»è³‡æœ¬ã‚³ã‚¹ãƒˆ * è‡ªå·±è³‡æœ¬æ¯”ç‡ + è² å‚µã‚³ã‚¹ãƒˆ * (1 - ç¨ç‡) * è² å‚µæ¯”ç‡`")
                    formula = indicators.get('formulas', {}).get('WACC', indicators.get('wacc', {}).get('reason'))
                    st.text(formula)
                    st.json({
                        "WACCè¨ˆç®—çµæœ": format_value(indicators.get('wacc', {}).get('value'), is_pct=True),
                        "æ ªä¸»è³‡æœ¬ã‚³ã‚¹ãƒˆ (Ke)": format_value(indicators.get('variables', {}).get('æ ªä¸»è³‡æœ¬ã‚³ã‚¹ãƒˆ'), is_pct=True),
                        "è² å‚µã‚³ã‚¹ãƒˆ (Kd)": format_value(indicators.get('variables', {}).get('è² å‚µã‚³ã‚¹ãƒˆ'), is_pct=True),
                        "ç¨ç‡": format_value(indicators.get('variables', {}).get('ç¨ç‡'), is_pct=True),
                        "ãƒ™ãƒ¼ã‚¿å€¤": f"{indicators.get('variables', {}).get('ãƒ™ãƒ¼ã‚¿å€¤'):.2f}" if isinstance(indicators.get('variables', {}).get('ãƒ™ãƒ¼ã‚¿å€¤'), (int,float)) else "N/A",
                        "ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆ": f"{st.session_state.rf_rate:.2%}",
                        "ãƒãƒ¼ã‚±ãƒƒãƒˆãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ": f"{mrp:.2%}"
                    })
                with tabs[7]:
                    st.subheader("PEGãƒ¬ã‚·ã‚ªã«åŸºã¥ãæŠ•è³‡å®¶ã‚³ãƒ¡ãƒ³ãƒˆ (ãƒªãƒ³ãƒ / ã‚¯ãƒ¬ã‚¤ãƒãƒ¼)")
                    commentary = get_peg_investor_commentary(indicators.get('peg', {}).get('value'))
                    st.markdown(commentary, unsafe_allow_html=True)
                with tabs[8]:
                    st.subheader("å°‚é–€å®¶ã‚³ãƒ¡ãƒ³ãƒˆ")
                    commentary = get_kiyohara_commentary(indicators.get('net_cash_ratio', {}).get('value'), indicators.get('cn_per', {}).get('value'), indicators.get('variables', {}).get('å½“æœŸç´”åˆ©ç›Š'))
                    st.markdown(commentary, unsafe_allow_html=True)
                with tabs[9]:
                    st.subheader("è²¡å‹™è«¸è¡¨ (ãƒãƒ•ã‚§ãƒƒãƒˆã‚³ãƒ¼ãƒ‰)")
                    bc_data = result.get('buffett_code_data', {})
                    pl_data, bs_data = bc_data.get('æç›Šè¨ˆç®—æ›¸', {}), bc_data.get('è²¸å€Ÿå¯¾ç…§è¡¨', {})
                    if pl_data or bs_data:
                        all_items = set()
                        if pl_data: all_items.update(list(pl_data.values())[0].keys())
                        if bs_data: all_items.update(list(bs_data.values())[0].keys())
                        periods = sorted(list(set(pl_data.keys()) | set(bs_data.keys())), reverse=True)
                        display_df = pd.DataFrame(index=sorted(list(all_items)), columns=periods)
                        for period in periods:
                            for item in display_df.index:
                                val = (pl_data.get(period, {}).get(item, {}) or bs_data.get(period, {}).get(item, {})).get('display')
                                display_df.loc[item, period] = val or "-"
                        st.dataframe(display_df)
                    else: st.warning("è²¡å‹™è«¸è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                with tabs[10]:
                    st.subheader("ãƒ¤ãƒ•ãƒ¼ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹è²¡å‹™ãƒ‡ãƒ¼ã‚¿")
                    yf_statements = result.get('yfinance_statements', {})
                    if yf_statements:
                        for title, df in yf_statements.items():
                            if not df.empty:
                                st.markdown(f"**{title}** (å˜ä½: ç™¾ä¸‡å††)")
                                st.dataframe(df.style.format("{:,.0f}", na_rep="-"))
                            else: st.markdown(f"**{title}**: ãƒ‡ãƒ¼ã‚¿ãªã—")
                    else: st.warning("Yahoo Financeã‹ã‚‰è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    st.markdown("---")
    st.header("ğŸ‘‘ æ™‚ä¾¡ç·é¡ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    ranking_data = []
    for display_key, result in all_results.items():
        if 'error' not in result and 'yf_info' in result:
            market_cap = result['yf_info'].get('marketCap')
            sector = result.get('sector', 'æ¥­ç¨®ä¸æ˜')
            if market_cap is not None:
                ranking_data.append({ "éŠ˜æŸ„": display_key, "æ¥­ç¨®": sector, "æ™‚ä¾¡ç·é¡": market_cap })
    if ranking_data:
        df_ranking = pd.DataFrame(ranking_data).sort_values(by="æ™‚ä¾¡ç·é¡", ascending=False)
        df_ranking.index = range(1, len(df_ranking) + 1)
        df_ranking.index.name = "é †ä½"
        def format_market_cap_display(cap):
            if cap >= 1_000_000_000_000: return f"{cap / 1_000_000_000_000:,.2f} å…†å††"
            return f"{cap / 100_000_000:,.2f} å„„å††"
        df_display = df_ranking.copy()
        df_display['æ™‚ä¾¡ç·é¡'] = df_display['æ™‚ä¾¡ç·é¡'].apply(format_market_cap_display)
        st.dataframe(df_display, use_container_width=True)
    else: st.info("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("---")
    st.header("ğŸ‘‘ ã‚ªãƒ¼ãƒŠãƒ¼çµŒå–¶è€… ä¿æœ‰å‰²åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    owner_executives = []
    for display_key, result in all_results.items():
        if 'error' in result: continue
        df_g = result.get('governance_df')
        if df_g is not None and not df_g.empty and 'å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)' in df_g.columns:
            owners = df_g[df_g['å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)'] > 0]
            if not owners.empty:
                top_owner = owners.loc[owners['å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)'].idxmax()]
                owner_executives.append({
                    'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰': result.get('ticker_code'), 'éŠ˜æŸ„å': result.get('company_name'),
                    'å½¹è·': top_owner['å½¹è·'], 'æ°å': top_owner['æ°å'], 'ä¿æœ‰å‰²åˆ (%)': top_owner['å¤§æ ªä¸»ã¨ã—ã¦ã®ä¿æœ‰å‰²åˆ (%)']
                })
    if owner_executives:
        ranking_df = pd.DataFrame(owner_executives).sort_values('ä¿æœ‰å‰²åˆ (%)', ascending=False).reset_index(drop=True)
        ranking_df.index += 1
        ranking_df.index.name = "é †ä½"
        st.dataframe(ranking_df.style.format({'ä¿æœ‰å‰²åˆ (%)': '{:.2f}%'}), use_container_width=True)
    else: st.info("åˆ†æã—ãŸéŠ˜æŸ„ã«ã€å¤§æ ªä¸»ã‚’å…¼ã­ã‚‹å½¹å“¡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    st.markdown("---")
    st.header("æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•æ¯”è¼ƒ")
    metrics_to_plot = ['EPS (å††)', 'EPSæˆé•·ç‡ (å¯¾å‰å¹´æ¯”) (%)', 'PER (å€)', 'PBR (å€)', 'ROE (%)', 'è‡ªå·±è³‡æœ¬æ¯”ç‡ (%)', 'å¹´é–“1æ ªé…å½“ (å††)', 'PEG (å®Ÿç¸¾)']
    selected_metric = st.selectbox("æ¯”è¼ƒã™ã‚‹æŒ‡æ¨™ã‚’é¸æŠã—ã¦ãã ã•ã„", metrics_to_plot, key="metric_selector")
    visible_stocks = []
    cols_check = st.columns(min(len(all_results.keys()), 4))
    for i, key in enumerate(all_results.keys()):
        if cols_check[i % len(cols_check)].checkbox(key, value=True, key=f"check_{key}"):
            visible_stocks.append(key)
    fig, ax = plt.subplots(figsize=(10, 6))
    color_list = plt.get_cmap('tab10').colors
    all_x_labels = set()
    for key in visible_stocks:
        if 'error' not in all_results.get(key, {}):
            if (df := all_results.get(key, {}).get('timeseries_df')) is not None and not df.empty and 'å¹´åº¦' in df.columns:
                all_x_labels.update(df['å¹´åº¦'].dropna().tolist())
    if all_x_labels and visible_stocks:
        sorted_x_labels = sorted(list(all_x_labels), key=lambda x: (x == 'æœ€æ–°', x))
        for i, key in enumerate(visible_stocks):
            if 'error' in all_results.get(key, {}): continue
            df = all_results[key].get('timeseries_df')
            if df is not None and not df.empty and 'å¹´åº¦' in df.columns:
                temp_df = df.set_index('å¹´åº¦')
                if selected_metric not in temp_df.columns: temp_df[selected_metric] = np.nan
                y_values = [temp_df.loc[label, selected_metric] if label in temp_df.index and pd.notna(temp_df.loc[label, selected_metric]) else np.nan for label in sorted_x_labels]
                y_series = pd.Series(y_values, index=range(len(sorted_x_labels))).interpolate(method='linear')
                line, = ax.plot(range(len(sorted_x_labels)), y_series.values, marker='', linestyle='-', label=key, color=color_list[i % len(color_list)])
                for x_idx, y_val in enumerate(pd.Series(y_values)):
                    if pd.notna(y_val):
                        ax.plot(x_idx, y_val, marker='o', color=line.get_color())
                        ax.annotate(f'{y_val:.2f}', (x_idx, y_val), textcoords="offset points", xytext=(0, 6), ha='center', fontsize=9)
        ymin, ymax = ax.get_ylim()
        span_alpha = 0.15
        if selected_metric == 'PBR (å€)': ax.axhspan(0, 1, facecolor='limegreen', alpha=span_alpha)
        elif selected_metric == 'PER (å€)': ax.axhspan(0, 10, facecolor='limegreen', alpha=span_alpha)
        elif selected_metric == 'ROE (%)': ax.axhspan(10, max(ymax, 11), facecolor='limegreen', alpha=span_alpha)
        elif selected_metric == 'PEG (å®Ÿç¸¾)': ax.axhspan(0, 1, facecolor='limegreen', alpha=span_alpha)
        elif selected_metric == 'è‡ªå·±è³‡æœ¬æ¯”ç‡ (%)': ax.axhspan(60, max(ymax, 11), facecolor='limegreen', alpha=span_alpha)
        elif selected_metric == 'EPSæˆé•·ç‡ (å¯¾å‰å¹´æ¯”) (%)': ax.axhspan(0, max(ymax, 1), facecolor='limegreen', alpha=span_alpha)
        ax.set_ylim(ymin, ymax)
        ax.set_title(f"{selected_metric} ã®æ™‚ç³»åˆ—æ¯”è¼ƒ", fontsize=16)
        ax.set_ylabel(selected_metric)
        ax.grid(True, which='both', linestyle='--', linewidth=0.5)
        ax.legend()
        ax.set_xticks(range(len(sorted_x_labels)))
        ax.set_xticklabels(sorted_x_labels, rotation=30, ha='right')
        st.pyplot(fig)
    else: st.warning("ã‚°ãƒ©ãƒ•ã‚’æç”»ã§ãã‚‹éŠ˜æŸ„ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

else:
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã¾ãŸã¯ä¼šç¤¾åã‚’å…¥åŠ›ã—ã¦ã€Œåˆ†æå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã‹ã€ã€ŒAIé¡ä¼¼éŠ˜æŸ„æ¤œç´¢ã€ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
